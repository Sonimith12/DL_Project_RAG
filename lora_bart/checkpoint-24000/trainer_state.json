{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9843322556577965,
  "eval_steps": 500,
  "global_step": 24000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012434717731907486,
      "grad_norm": 1.764473557472229,
      "learning_rate": 4.979275470446821e-05,
      "loss": 10.1931,
      "step": 100
    },
    {
      "epoch": 0.02486943546381497,
      "grad_norm": 10.225044250488281,
      "learning_rate": 4.958550940893642e-05,
      "loss": 7.2535,
      "step": 200
    },
    {
      "epoch": 0.03730415319572246,
      "grad_norm": 0.9976806640625,
      "learning_rate": 4.937826411340463e-05,
      "loss": 5.8824,
      "step": 300
    },
    {
      "epoch": 0.04973887092762994,
      "grad_norm": 1.073211669921875,
      "learning_rate": 4.917101881787284e-05,
      "loss": 5.5312,
      "step": 400
    },
    {
      "epoch": 0.062173588659537427,
      "grad_norm": 1.1006888151168823,
      "learning_rate": 4.896377352234105e-05,
      "loss": 5.4647,
      "step": 500
    },
    {
      "epoch": 0.07460830639144492,
      "grad_norm": 1.0413936376571655,
      "learning_rate": 4.8756528226809256e-05,
      "loss": 5.4534,
      "step": 600
    },
    {
      "epoch": 0.0870430241233524,
      "grad_norm": 1.9837549924850464,
      "learning_rate": 4.8549282931277465e-05,
      "loss": 5.4552,
      "step": 700
    },
    {
      "epoch": 0.09947774185525989,
      "grad_norm": 0.7701225280761719,
      "learning_rate": 4.834203763574567e-05,
      "loss": 5.4181,
      "step": 800
    },
    {
      "epoch": 0.11191245958716738,
      "grad_norm": 0.8537407517433167,
      "learning_rate": 4.813479234021388e-05,
      "loss": 5.4723,
      "step": 900
    },
    {
      "epoch": 0.12434717731907485,
      "grad_norm": 1.236843228340149,
      "learning_rate": 4.7927547044682086e-05,
      "loss": 5.4389,
      "step": 1000
    },
    {
      "epoch": 0.13678189505098234,
      "grad_norm": 0.7720403075218201,
      "learning_rate": 4.7720301749150295e-05,
      "loss": 5.3826,
      "step": 1100
    },
    {
      "epoch": 0.14921661278288983,
      "grad_norm": 0.8593823909759521,
      "learning_rate": 4.7513056453618504e-05,
      "loss": 5.3903,
      "step": 1200
    },
    {
      "epoch": 0.16165133051479733,
      "grad_norm": 0.8130382895469666,
      "learning_rate": 4.730581115808671e-05,
      "loss": 5.3921,
      "step": 1300
    },
    {
      "epoch": 0.1740860482467048,
      "grad_norm": 0.7143875956535339,
      "learning_rate": 4.709856586255492e-05,
      "loss": 5.5291,
      "step": 1400
    },
    {
      "epoch": 0.18652076597861228,
      "grad_norm": 0.6661285758018494,
      "learning_rate": 4.689132056702313e-05,
      "loss": 5.396,
      "step": 1500
    },
    {
      "epoch": 0.19895548371051977,
      "grad_norm": 0.9842315912246704,
      "learning_rate": 4.668407527149134e-05,
      "loss": 5.3406,
      "step": 1600
    },
    {
      "epoch": 0.21139020144242726,
      "grad_norm": 0.6052118539810181,
      "learning_rate": 4.647682997595955e-05,
      "loss": 5.4114,
      "step": 1700
    },
    {
      "epoch": 0.22382491917433475,
      "grad_norm": 0.9289252161979675,
      "learning_rate": 4.626958468042776e-05,
      "loss": 5.3023,
      "step": 1800
    },
    {
      "epoch": 0.23625963690624222,
      "grad_norm": 0.6849111914634705,
      "learning_rate": 4.606233938489597e-05,
      "loss": 5.395,
      "step": 1900
    },
    {
      "epoch": 0.2486943546381497,
      "grad_norm": 0.8423449993133545,
      "learning_rate": 4.5855094089364176e-05,
      "loss": 5.3892,
      "step": 2000
    },
    {
      "epoch": 0.2611290723700572,
      "grad_norm": 0.8169329762458801,
      "learning_rate": 4.5647848793832385e-05,
      "loss": 5.3122,
      "step": 2100
    },
    {
      "epoch": 0.2735637901019647,
      "grad_norm": 0.8560545444488525,
      "learning_rate": 4.5440603498300594e-05,
      "loss": 5.4606,
      "step": 2200
    },
    {
      "epoch": 0.28599850783387215,
      "grad_norm": 0.6172865629196167,
      "learning_rate": 4.52333582027688e-05,
      "loss": 5.3581,
      "step": 2300
    },
    {
      "epoch": 0.29843322556577967,
      "grad_norm": 0.9053509831428528,
      "learning_rate": 4.5026112907237005e-05,
      "loss": 5.4657,
      "step": 2400
    },
    {
      "epoch": 0.31086794329768713,
      "grad_norm": 0.8910143375396729,
      "learning_rate": 4.4818867611705214e-05,
      "loss": 5.4128,
      "step": 2500
    },
    {
      "epoch": 0.32330266102959465,
      "grad_norm": 1.067020297050476,
      "learning_rate": 4.461162231617342e-05,
      "loss": 5.4858,
      "step": 2600
    },
    {
      "epoch": 0.3357373787615021,
      "grad_norm": 0.6996538639068604,
      "learning_rate": 4.440437702064163e-05,
      "loss": 5.4345,
      "step": 2700
    },
    {
      "epoch": 0.3481720964934096,
      "grad_norm": 1.078623652458191,
      "learning_rate": 4.419713172510984e-05,
      "loss": 5.3737,
      "step": 2800
    },
    {
      "epoch": 0.3606068142253171,
      "grad_norm": 1.1986711025238037,
      "learning_rate": 4.398988642957805e-05,
      "loss": 5.3164,
      "step": 2900
    },
    {
      "epoch": 0.37304153195722456,
      "grad_norm": 1.2480477094650269,
      "learning_rate": 4.378264113404626e-05,
      "loss": 5.3398,
      "step": 3000
    },
    {
      "epoch": 0.3854762496891321,
      "grad_norm": 0.6182315349578857,
      "learning_rate": 4.357539583851447e-05,
      "loss": 5.3711,
      "step": 3100
    },
    {
      "epoch": 0.39791096742103954,
      "grad_norm": 1.3486472368240356,
      "learning_rate": 4.336815054298268e-05,
      "loss": 5.334,
      "step": 3200
    },
    {
      "epoch": 0.410345685152947,
      "grad_norm": 0.9116904139518738,
      "learning_rate": 4.3160905247450886e-05,
      "loss": 5.3379,
      "step": 3300
    },
    {
      "epoch": 0.4227804028848545,
      "grad_norm": 0.8826619982719421,
      "learning_rate": 4.2953659951919095e-05,
      "loss": 5.4147,
      "step": 3400
    },
    {
      "epoch": 0.435215120616762,
      "grad_norm": 0.9689586758613586,
      "learning_rate": 4.2746414656387304e-05,
      "loss": 5.3423,
      "step": 3500
    },
    {
      "epoch": 0.4476498383486695,
      "grad_norm": 0.8302145004272461,
      "learning_rate": 4.253916936085551e-05,
      "loss": 5.2654,
      "step": 3600
    },
    {
      "epoch": 0.46008455608057697,
      "grad_norm": 1.1882894039154053,
      "learning_rate": 4.233192406532372e-05,
      "loss": 5.3468,
      "step": 3700
    },
    {
      "epoch": 0.47251927381248443,
      "grad_norm": 1.0803437232971191,
      "learning_rate": 4.2124678769791925e-05,
      "loss": 5.3336,
      "step": 3800
    },
    {
      "epoch": 0.48495399154439195,
      "grad_norm": 0.7742570042610168,
      "learning_rate": 4.191743347426014e-05,
      "loss": 5.371,
      "step": 3900
    },
    {
      "epoch": 0.4973887092762994,
      "grad_norm": 0.9223662614822388,
      "learning_rate": 4.171018817872834e-05,
      "loss": 5.3326,
      "step": 4000
    },
    {
      "epoch": 0.5098234270082069,
      "grad_norm": 0.9913396835327148,
      "learning_rate": 4.150294288319655e-05,
      "loss": 5.3443,
      "step": 4100
    },
    {
      "epoch": 0.5222581447401144,
      "grad_norm": 0.6563533544540405,
      "learning_rate": 4.129569758766476e-05,
      "loss": 5.3213,
      "step": 4200
    },
    {
      "epoch": 0.5346928624720219,
      "grad_norm": 0.9031338691711426,
      "learning_rate": 4.108845229213297e-05,
      "loss": 5.2452,
      "step": 4300
    },
    {
      "epoch": 0.5471275802039294,
      "grad_norm": 0.7814847230911255,
      "learning_rate": 4.088120699660118e-05,
      "loss": 5.3811,
      "step": 4400
    },
    {
      "epoch": 0.5595622979358369,
      "grad_norm": 2.0277934074401855,
      "learning_rate": 4.067396170106939e-05,
      "loss": 5.3447,
      "step": 4500
    },
    {
      "epoch": 0.5719970156677443,
      "grad_norm": 0.7836811542510986,
      "learning_rate": 4.04667164055376e-05,
      "loss": 5.3748,
      "step": 4600
    },
    {
      "epoch": 0.5844317333996518,
      "grad_norm": 0.7947938442230225,
      "learning_rate": 4.0259471110005806e-05,
      "loss": 5.3833,
      "step": 4700
    },
    {
      "epoch": 0.5968664511315593,
      "grad_norm": 1.7654553651809692,
      "learning_rate": 4.0052225814474015e-05,
      "loss": 5.3355,
      "step": 4800
    },
    {
      "epoch": 0.6093011688634667,
      "grad_norm": 0.9386829733848572,
      "learning_rate": 3.9844980518942224e-05,
      "loss": 5.396,
      "step": 4900
    },
    {
      "epoch": 0.6217358865953743,
      "grad_norm": 0.8018089532852173,
      "learning_rate": 3.963773522341043e-05,
      "loss": 5.3187,
      "step": 5000
    },
    {
      "epoch": 0.6341706043272818,
      "grad_norm": 2.040489673614502,
      "learning_rate": 3.943048992787864e-05,
      "loss": 5.3846,
      "step": 5100
    },
    {
      "epoch": 0.6466053220591893,
      "grad_norm": 1.1542110443115234,
      "learning_rate": 3.9223244632346844e-05,
      "loss": 5.3849,
      "step": 5200
    },
    {
      "epoch": 0.6590400397910967,
      "grad_norm": 0.7259002327919006,
      "learning_rate": 3.901599933681506e-05,
      "loss": 5.3401,
      "step": 5300
    },
    {
      "epoch": 0.6714747575230042,
      "grad_norm": 0.7996181845664978,
      "learning_rate": 3.880875404128326e-05,
      "loss": 5.2706,
      "step": 5400
    },
    {
      "epoch": 0.6839094752549117,
      "grad_norm": 1.1479790210723877,
      "learning_rate": 3.860150874575148e-05,
      "loss": 5.3861,
      "step": 5500
    },
    {
      "epoch": 0.6963441929868192,
      "grad_norm": 0.9280735850334167,
      "learning_rate": 3.839426345021968e-05,
      "loss": 5.2821,
      "step": 5600
    },
    {
      "epoch": 0.7087789107187267,
      "grad_norm": 1.339408278465271,
      "learning_rate": 3.8187018154687896e-05,
      "loss": 5.3707,
      "step": 5700
    },
    {
      "epoch": 0.7212136284506342,
      "grad_norm": 1.0276745557785034,
      "learning_rate": 3.79797728591561e-05,
      "loss": 5.4152,
      "step": 5800
    },
    {
      "epoch": 0.7336483461825417,
      "grad_norm": 0.8577404022216797,
      "learning_rate": 3.777252756362431e-05,
      "loss": 5.3126,
      "step": 5900
    },
    {
      "epoch": 0.7460830639144491,
      "grad_norm": 0.9375118613243103,
      "learning_rate": 3.7565282268092516e-05,
      "loss": 5.3233,
      "step": 6000
    },
    {
      "epoch": 0.7585177816463566,
      "grad_norm": 0.82365483045578,
      "learning_rate": 3.7358036972560725e-05,
      "loss": 5.4214,
      "step": 6100
    },
    {
      "epoch": 0.7709524993782642,
      "grad_norm": 1.0028190612792969,
      "learning_rate": 3.7150791677028934e-05,
      "loss": 5.3166,
      "step": 6200
    },
    {
      "epoch": 0.7833872171101716,
      "grad_norm": 1.2454602718353271,
      "learning_rate": 3.694354638149714e-05,
      "loss": 5.3586,
      "step": 6300
    },
    {
      "epoch": 0.7958219348420791,
      "grad_norm": 1.2184423208236694,
      "learning_rate": 3.673630108596535e-05,
      "loss": 5.3685,
      "step": 6400
    },
    {
      "epoch": 0.8082566525739866,
      "grad_norm": 1.4164327383041382,
      "learning_rate": 3.652905579043356e-05,
      "loss": 5.3708,
      "step": 6500
    },
    {
      "epoch": 0.820691370305894,
      "grad_norm": 1.1313562393188477,
      "learning_rate": 3.632181049490177e-05,
      "loss": 5.3391,
      "step": 6600
    },
    {
      "epoch": 0.8331260880378015,
      "grad_norm": 1.0222396850585938,
      "learning_rate": 3.611456519936998e-05,
      "loss": 5.3153,
      "step": 6700
    },
    {
      "epoch": 0.845560805769709,
      "grad_norm": 0.7160531878471375,
      "learning_rate": 3.590731990383818e-05,
      "loss": 5.3948,
      "step": 6800
    },
    {
      "epoch": 0.8579955235016166,
      "grad_norm": 0.8922369480133057,
      "learning_rate": 3.57000746083064e-05,
      "loss": 5.3376,
      "step": 6900
    },
    {
      "epoch": 0.870430241233524,
      "grad_norm": 0.9546387791633606,
      "learning_rate": 3.54928293127746e-05,
      "loss": 5.3625,
      "step": 7000
    },
    {
      "epoch": 0.8828649589654315,
      "grad_norm": 1.253188967704773,
      "learning_rate": 3.5285584017242815e-05,
      "loss": 5.3766,
      "step": 7100
    },
    {
      "epoch": 0.895299676697339,
      "grad_norm": 0.9362509846687317,
      "learning_rate": 3.507833872171102e-05,
      "loss": 5.3798,
      "step": 7200
    },
    {
      "epoch": 0.9077343944292464,
      "grad_norm": 1.0159944295883179,
      "learning_rate": 3.487109342617923e-05,
      "loss": 5.3472,
      "step": 7300
    },
    {
      "epoch": 0.9201691121611539,
      "grad_norm": 1.317291498184204,
      "learning_rate": 3.4663848130647436e-05,
      "loss": 5.322,
      "step": 7400
    },
    {
      "epoch": 0.9326038298930615,
      "grad_norm": 0.7210010290145874,
      "learning_rate": 3.4456602835115645e-05,
      "loss": 5.3777,
      "step": 7500
    },
    {
      "epoch": 0.9450385476249689,
      "grad_norm": 1.2017399072647095,
      "learning_rate": 3.4249357539583854e-05,
      "loss": 5.3104,
      "step": 7600
    },
    {
      "epoch": 0.9574732653568764,
      "grad_norm": 11.844913482666016,
      "learning_rate": 3.404211224405206e-05,
      "loss": 5.3285,
      "step": 7700
    },
    {
      "epoch": 0.9699079830887839,
      "grad_norm": 1.0126756429672241,
      "learning_rate": 3.383486694852027e-05,
      "loss": 5.3086,
      "step": 7800
    },
    {
      "epoch": 0.9823427008206914,
      "grad_norm": 1.4916006326675415,
      "learning_rate": 3.362762165298848e-05,
      "loss": 5.3419,
      "step": 7900
    },
    {
      "epoch": 0.9947774185525988,
      "grad_norm": 0.9378414154052734,
      "learning_rate": 3.342037635745669e-05,
      "loss": 5.2853,
      "step": 8000
    },
    {
      "epoch": 1.0072121362845063,
      "grad_norm": 0.8451586961746216,
      "learning_rate": 3.32131310619249e-05,
      "loss": 5.3185,
      "step": 8100
    },
    {
      "epoch": 1.0196468540164139,
      "grad_norm": 1.2372183799743652,
      "learning_rate": 3.30058857663931e-05,
      "loss": 5.4008,
      "step": 8200
    },
    {
      "epoch": 1.0320815717483214,
      "grad_norm": 0.9870657920837402,
      "learning_rate": 3.279864047086132e-05,
      "loss": 5.2756,
      "step": 8300
    },
    {
      "epoch": 1.044516289480229,
      "grad_norm": 1.6122392416000366,
      "learning_rate": 3.259139517532952e-05,
      "loss": 5.3378,
      "step": 8400
    },
    {
      "epoch": 1.0569510072121362,
      "grad_norm": 1.2557786703109741,
      "learning_rate": 3.2384149879797735e-05,
      "loss": 5.3079,
      "step": 8500
    },
    {
      "epoch": 1.0693857249440437,
      "grad_norm": 0.8807662725448608,
      "learning_rate": 3.217690458426594e-05,
      "loss": 5.3269,
      "step": 8600
    },
    {
      "epoch": 1.0818204426759512,
      "grad_norm": 1.3039129972457886,
      "learning_rate": 3.196965928873415e-05,
      "loss": 5.3555,
      "step": 8700
    },
    {
      "epoch": 1.0942551604078588,
      "grad_norm": 1.9796116352081299,
      "learning_rate": 3.1762413993202355e-05,
      "loss": 5.3164,
      "step": 8800
    },
    {
      "epoch": 1.1066898781397663,
      "grad_norm": 1.1287943124771118,
      "learning_rate": 3.1555168697670564e-05,
      "loss": 5.3326,
      "step": 8900
    },
    {
      "epoch": 1.1191245958716738,
      "grad_norm": 1.7820361852645874,
      "learning_rate": 3.134792340213877e-05,
      "loss": 5.2962,
      "step": 9000
    },
    {
      "epoch": 1.131559313603581,
      "grad_norm": 0.866040825843811,
      "learning_rate": 3.114067810660698e-05,
      "loss": 5.352,
      "step": 9100
    },
    {
      "epoch": 1.1439940313354886,
      "grad_norm": 1.1472384929656982,
      "learning_rate": 3.093343281107519e-05,
      "loss": 5.3319,
      "step": 9200
    },
    {
      "epoch": 1.1564287490673961,
      "grad_norm": 0.7901968955993652,
      "learning_rate": 3.07261875155434e-05,
      "loss": 5.3293,
      "step": 9300
    },
    {
      "epoch": 1.1688634667993036,
      "grad_norm": 1.0277934074401855,
      "learning_rate": 3.051894222001161e-05,
      "loss": 5.3435,
      "step": 9400
    },
    {
      "epoch": 1.1812981845312112,
      "grad_norm": 4.0018310546875,
      "learning_rate": 3.0311696924479815e-05,
      "loss": 5.3695,
      "step": 9500
    },
    {
      "epoch": 1.1937329022631187,
      "grad_norm": 1.180566668510437,
      "learning_rate": 3.010445162894802e-05,
      "loss": 5.3417,
      "step": 9600
    },
    {
      "epoch": 1.2061676199950262,
      "grad_norm": 1.1882691383361816,
      "learning_rate": 2.9897206333416233e-05,
      "loss": 5.3333,
      "step": 9700
    },
    {
      "epoch": 1.2186023377269337,
      "grad_norm": 1.322065830230713,
      "learning_rate": 2.9689961037884438e-05,
      "loss": 5.303,
      "step": 9800
    },
    {
      "epoch": 1.231037055458841,
      "grad_norm": 0.9385985136032104,
      "learning_rate": 2.948271574235265e-05,
      "loss": 5.2972,
      "step": 9900
    },
    {
      "epoch": 1.2434717731907485,
      "grad_norm": 5.906315803527832,
      "learning_rate": 2.9275470446820856e-05,
      "loss": 5.4259,
      "step": 10000
    },
    {
      "epoch": 1.255906490922656,
      "grad_norm": 2.3335883617401123,
      "learning_rate": 2.906822515128907e-05,
      "loss": 5.3193,
      "step": 10100
    },
    {
      "epoch": 1.2683412086545636,
      "grad_norm": 0.9611216187477112,
      "learning_rate": 2.8860979855757274e-05,
      "loss": 5.352,
      "step": 10200
    },
    {
      "epoch": 1.280775926386471,
      "grad_norm": 1.2280112504959106,
      "learning_rate": 2.8653734560225487e-05,
      "loss": 5.3885,
      "step": 10300
    },
    {
      "epoch": 1.2932106441183784,
      "grad_norm": 1.8533382415771484,
      "learning_rate": 2.8446489264693692e-05,
      "loss": 5.3355,
      "step": 10400
    },
    {
      "epoch": 1.305645361850286,
      "grad_norm": 0.856956958770752,
      "learning_rate": 2.8239243969161898e-05,
      "loss": 5.3221,
      "step": 10500
    },
    {
      "epoch": 1.3180800795821934,
      "grad_norm": 1.0276801586151123,
      "learning_rate": 2.803199867363011e-05,
      "loss": 5.28,
      "step": 10600
    },
    {
      "epoch": 1.330514797314101,
      "grad_norm": 1.4456522464752197,
      "learning_rate": 2.7824753378098316e-05,
      "loss": 5.3177,
      "step": 10700
    },
    {
      "epoch": 1.3429495150460085,
      "grad_norm": 0.8967886567115784,
      "learning_rate": 2.761750808256653e-05,
      "loss": 5.3108,
      "step": 10800
    },
    {
      "epoch": 1.355384232777916,
      "grad_norm": 1.5540047883987427,
      "learning_rate": 2.7410262787034734e-05,
      "loss": 5.3683,
      "step": 10900
    },
    {
      "epoch": 1.3678189505098235,
      "grad_norm": 1.1090062856674194,
      "learning_rate": 2.7203017491502946e-05,
      "loss": 5.3128,
      "step": 11000
    },
    {
      "epoch": 1.380253668241731,
      "grad_norm": 0.8902953863143921,
      "learning_rate": 2.6995772195971152e-05,
      "loss": 5.3139,
      "step": 11100
    },
    {
      "epoch": 1.3926883859736385,
      "grad_norm": 2.117403984069824,
      "learning_rate": 2.6788526900439358e-05,
      "loss": 5.3329,
      "step": 11200
    },
    {
      "epoch": 1.4051231037055458,
      "grad_norm": 1.3578373193740845,
      "learning_rate": 2.658128160490757e-05,
      "loss": 5.3361,
      "step": 11300
    },
    {
      "epoch": 1.4175578214374533,
      "grad_norm": 0.6854958534240723,
      "learning_rate": 2.6374036309375776e-05,
      "loss": 5.3332,
      "step": 11400
    },
    {
      "epoch": 1.4299925391693609,
      "grad_norm": 1.3756976127624512,
      "learning_rate": 2.6166791013843988e-05,
      "loss": 5.3302,
      "step": 11500
    },
    {
      "epoch": 1.4424272569012684,
      "grad_norm": 0.9807008504867554,
      "learning_rate": 2.5959545718312194e-05,
      "loss": 5.2311,
      "step": 11600
    },
    {
      "epoch": 1.454861974633176,
      "grad_norm": 1.1930814981460571,
      "learning_rate": 2.5752300422780406e-05,
      "loss": 5.2224,
      "step": 11700
    },
    {
      "epoch": 1.4672966923650832,
      "grad_norm": 0.9650065302848816,
      "learning_rate": 2.5545055127248612e-05,
      "loss": 5.3229,
      "step": 11800
    },
    {
      "epoch": 1.4797314100969907,
      "grad_norm": 1.6066715717315674,
      "learning_rate": 2.5337809831716817e-05,
      "loss": 5.2857,
      "step": 11900
    },
    {
      "epoch": 1.4921661278288982,
      "grad_norm": 0.6591705083847046,
      "learning_rate": 2.513056453618503e-05,
      "loss": 5.3049,
      "step": 12000
    },
    {
      "epoch": 1.5046008455608058,
      "grad_norm": 1.239657998085022,
      "learning_rate": 2.492331924065324e-05,
      "loss": 5.3641,
      "step": 12100
    },
    {
      "epoch": 1.5170355632927133,
      "grad_norm": 0.6987063884735107,
      "learning_rate": 2.4716073945121444e-05,
      "loss": 5.3722,
      "step": 12200
    },
    {
      "epoch": 1.5294702810246208,
      "grad_norm": 1.0112006664276123,
      "learning_rate": 2.4508828649589653e-05,
      "loss": 5.3233,
      "step": 12300
    },
    {
      "epoch": 1.5419049987565283,
      "grad_norm": 2.625256299972534,
      "learning_rate": 2.4301583354057862e-05,
      "loss": 5.3245,
      "step": 12400
    },
    {
      "epoch": 1.5543397164884358,
      "grad_norm": 0.8251312971115112,
      "learning_rate": 2.409433805852607e-05,
      "loss": 5.3196,
      "step": 12500
    },
    {
      "epoch": 1.5667744342203433,
      "grad_norm": 0.9039039611816406,
      "learning_rate": 2.388709276299428e-05,
      "loss": 5.3451,
      "step": 12600
    },
    {
      "epoch": 1.5792091519522506,
      "grad_norm": 1.1428252458572388,
      "learning_rate": 2.367984746746249e-05,
      "loss": 5.3513,
      "step": 12700
    },
    {
      "epoch": 1.5916438696841582,
      "grad_norm": 1.231689453125,
      "learning_rate": 2.34726021719307e-05,
      "loss": 5.321,
      "step": 12800
    },
    {
      "epoch": 1.6040785874160657,
      "grad_norm": 1.4865764379501343,
      "learning_rate": 2.3265356876398904e-05,
      "loss": 5.3397,
      "step": 12900
    },
    {
      "epoch": 1.616513305147973,
      "grad_norm": 1.111538052558899,
      "learning_rate": 2.3058111580867113e-05,
      "loss": 5.3367,
      "step": 13000
    },
    {
      "epoch": 1.6289480228798805,
      "grad_norm": 5.248116970062256,
      "learning_rate": 2.2850866285335322e-05,
      "loss": 5.2903,
      "step": 13100
    },
    {
      "epoch": 1.641382740611788,
      "grad_norm": 1.1890984773635864,
      "learning_rate": 2.264362098980353e-05,
      "loss": 5.3758,
      "step": 13200
    },
    {
      "epoch": 1.6538174583436955,
      "grad_norm": 1.1129027605056763,
      "learning_rate": 2.243637569427174e-05,
      "loss": 5.3168,
      "step": 13300
    },
    {
      "epoch": 1.666252176075603,
      "grad_norm": 0.8164961934089661,
      "learning_rate": 2.222913039873995e-05,
      "loss": 5.3615,
      "step": 13400
    },
    {
      "epoch": 1.6786868938075106,
      "grad_norm": 1.2066571712493896,
      "learning_rate": 2.2021885103208158e-05,
      "loss": 5.3039,
      "step": 13500
    },
    {
      "epoch": 1.691121611539418,
      "grad_norm": 0.8610196709632874,
      "learning_rate": 2.1814639807676367e-05,
      "loss": 5.3063,
      "step": 13600
    },
    {
      "epoch": 1.7035563292713256,
      "grad_norm": 1.260260820388794,
      "learning_rate": 2.1607394512144573e-05,
      "loss": 5.317,
      "step": 13700
    },
    {
      "epoch": 1.7159910470032331,
      "grad_norm": 1.097493290901184,
      "learning_rate": 2.1400149216612782e-05,
      "loss": 5.23,
      "step": 13800
    },
    {
      "epoch": 1.7284257647351406,
      "grad_norm": 0.6888590455055237,
      "learning_rate": 2.119290392108099e-05,
      "loss": 5.3119,
      "step": 13900
    },
    {
      "epoch": 1.740860482467048,
      "grad_norm": 1.08603835105896,
      "learning_rate": 2.09856586255492e-05,
      "loss": 5.3789,
      "step": 14000
    },
    {
      "epoch": 1.7532952001989555,
      "grad_norm": 1.1476576328277588,
      "learning_rate": 2.077841333001741e-05,
      "loss": 5.3802,
      "step": 14100
    },
    {
      "epoch": 1.765729917930863,
      "grad_norm": 0.6440299153327942,
      "learning_rate": 2.0571168034485618e-05,
      "loss": 5.3626,
      "step": 14200
    },
    {
      "epoch": 1.7781646356627705,
      "grad_norm": 0.6740097403526306,
      "learning_rate": 2.0363922738953827e-05,
      "loss": 5.356,
      "step": 14300
    },
    {
      "epoch": 1.7905993533946778,
      "grad_norm": 1.135877013206482,
      "learning_rate": 2.0156677443422033e-05,
      "loss": 5.2847,
      "step": 14400
    },
    {
      "epoch": 1.8030340711265853,
      "grad_norm": 0.5593398213386536,
      "learning_rate": 1.994943214789024e-05,
      "loss": 5.3372,
      "step": 14500
    },
    {
      "epoch": 1.8154687888584928,
      "grad_norm": 0.8160482048988342,
      "learning_rate": 1.974218685235845e-05,
      "loss": 5.3282,
      "step": 14600
    },
    {
      "epoch": 1.8279035065904004,
      "grad_norm": 1.610289216041565,
      "learning_rate": 1.953494155682666e-05,
      "loss": 5.256,
      "step": 14700
    },
    {
      "epoch": 1.8403382243223079,
      "grad_norm": 4.266801357269287,
      "learning_rate": 1.932769626129487e-05,
      "loss": 5.3052,
      "step": 14800
    },
    {
      "epoch": 1.8527729420542154,
      "grad_norm": 1.0607339143753052,
      "learning_rate": 1.9120450965763078e-05,
      "loss": 5.322,
      "step": 14900
    },
    {
      "epoch": 1.865207659786123,
      "grad_norm": 1.1975053548812866,
      "learning_rate": 1.8913205670231287e-05,
      "loss": 5.2725,
      "step": 15000
    },
    {
      "epoch": 1.8776423775180304,
      "grad_norm": 1.1750092506408691,
      "learning_rate": 1.8705960374699496e-05,
      "loss": 5.2697,
      "step": 15100
    },
    {
      "epoch": 1.890077095249938,
      "grad_norm": 0.9242594838142395,
      "learning_rate": 1.84987150791677e-05,
      "loss": 5.1815,
      "step": 15200
    },
    {
      "epoch": 1.9025118129818455,
      "grad_norm": 0.5833956599235535,
      "learning_rate": 1.829146978363591e-05,
      "loss": 5.3815,
      "step": 15300
    },
    {
      "epoch": 1.9149465307137528,
      "grad_norm": 0.991146981716156,
      "learning_rate": 1.808422448810412e-05,
      "loss": 5.3308,
      "step": 15400
    },
    {
      "epoch": 1.9273812484456603,
      "grad_norm": 0.626882016658783,
      "learning_rate": 1.787697919257233e-05,
      "loss": 5.334,
      "step": 15500
    },
    {
      "epoch": 1.9398159661775678,
      "grad_norm": 1.0714703798294067,
      "learning_rate": 1.7669733897040537e-05,
      "loss": 5.3334,
      "step": 15600
    },
    {
      "epoch": 1.952250683909475,
      "grad_norm": 5.719034194946289,
      "learning_rate": 1.7462488601508746e-05,
      "loss": 5.3298,
      "step": 15700
    },
    {
      "epoch": 1.9646854016413826,
      "grad_norm": 0.6155217885971069,
      "learning_rate": 1.7255243305976955e-05,
      "loss": 5.3442,
      "step": 15800
    },
    {
      "epoch": 1.9771201193732901,
      "grad_norm": 0.6218103766441345,
      "learning_rate": 1.704799801044516e-05,
      "loss": 5.2866,
      "step": 15900
    },
    {
      "epoch": 1.9895548371051976,
      "grad_norm": 1.3093265295028687,
      "learning_rate": 1.684075271491337e-05,
      "loss": 5.3608,
      "step": 16000
    },
    {
      "epoch": 2.001989554837105,
      "grad_norm": 0.9899680614471436,
      "learning_rate": 1.663350741938158e-05,
      "loss": 5.3431,
      "step": 16100
    },
    {
      "epoch": 2.0144242725690127,
      "grad_norm": 1.0916314125061035,
      "learning_rate": 1.6426262123849788e-05,
      "loss": 5.2966,
      "step": 16200
    },
    {
      "epoch": 2.02685899030092,
      "grad_norm": 0.6418160796165466,
      "learning_rate": 1.6219016828317997e-05,
      "loss": 5.3724,
      "step": 16300
    },
    {
      "epoch": 2.0392937080328277,
      "grad_norm": 0.6333214044570923,
      "learning_rate": 1.6011771532786206e-05,
      "loss": 5.3716,
      "step": 16400
    },
    {
      "epoch": 2.0517284257647352,
      "grad_norm": 0.7493649125099182,
      "learning_rate": 1.5804526237254415e-05,
      "loss": 5.3262,
      "step": 16500
    },
    {
      "epoch": 2.0641631434966428,
      "grad_norm": 0.9894953966140747,
      "learning_rate": 1.559728094172262e-05,
      "loss": 5.2555,
      "step": 16600
    },
    {
      "epoch": 2.0765978612285503,
      "grad_norm": 1.4784388542175293,
      "learning_rate": 1.539003564619083e-05,
      "loss": 5.2623,
      "step": 16700
    },
    {
      "epoch": 2.089032578960458,
      "grad_norm": 1.4928029775619507,
      "learning_rate": 1.518279035065904e-05,
      "loss": 5.392,
      "step": 16800
    },
    {
      "epoch": 2.101467296692365,
      "grad_norm": 0.7646583318710327,
      "learning_rate": 1.497554505512725e-05,
      "loss": 5.3112,
      "step": 16900
    },
    {
      "epoch": 2.1139020144242724,
      "grad_norm": 0.7080554366111755,
      "learning_rate": 1.4768299759595458e-05,
      "loss": 5.366,
      "step": 17000
    },
    {
      "epoch": 2.12633673215618,
      "grad_norm": 0.7214729189872742,
      "learning_rate": 1.4561054464063667e-05,
      "loss": 5.3626,
      "step": 17100
    },
    {
      "epoch": 2.1387714498880874,
      "grad_norm": 0.980205237865448,
      "learning_rate": 1.4353809168531876e-05,
      "loss": 5.3403,
      "step": 17200
    },
    {
      "epoch": 2.151206167619995,
      "grad_norm": 0.7630121111869812,
      "learning_rate": 1.4146563873000085e-05,
      "loss": 5.295,
      "step": 17300
    },
    {
      "epoch": 2.1636408853519025,
      "grad_norm": 0.981818675994873,
      "learning_rate": 1.3939318577468291e-05,
      "loss": 5.3524,
      "step": 17400
    },
    {
      "epoch": 2.17607560308381,
      "grad_norm": 1.1161919832229614,
      "learning_rate": 1.37320732819365e-05,
      "loss": 5.2875,
      "step": 17500
    },
    {
      "epoch": 2.1885103208157175,
      "grad_norm": 0.6772276759147644,
      "learning_rate": 1.3524827986404709e-05,
      "loss": 5.3095,
      "step": 17600
    },
    {
      "epoch": 2.200945038547625,
      "grad_norm": 1.8582392930984497,
      "learning_rate": 1.3317582690872918e-05,
      "loss": 5.3308,
      "step": 17700
    },
    {
      "epoch": 2.2133797562795325,
      "grad_norm": 0.8099024295806885,
      "learning_rate": 1.3110337395341127e-05,
      "loss": 5.3553,
      "step": 17800
    },
    {
      "epoch": 2.22581447401144,
      "grad_norm": 0.7146322727203369,
      "learning_rate": 1.2903092099809336e-05,
      "loss": 5.3227,
      "step": 17900
    },
    {
      "epoch": 2.2382491917433476,
      "grad_norm": 0.7196874022483826,
      "learning_rate": 1.2695846804277545e-05,
      "loss": 5.3154,
      "step": 18000
    },
    {
      "epoch": 2.250683909475255,
      "grad_norm": 0.7344927787780762,
      "learning_rate": 1.2488601508745753e-05,
      "loss": 5.3012,
      "step": 18100
    },
    {
      "epoch": 2.263118627207162,
      "grad_norm": 0.8947378396987915,
      "learning_rate": 1.2281356213213962e-05,
      "loss": 5.2917,
      "step": 18200
    },
    {
      "epoch": 2.2755533449390697,
      "grad_norm": 0.9666973948478699,
      "learning_rate": 1.2074110917682169e-05,
      "loss": 5.3436,
      "step": 18300
    },
    {
      "epoch": 2.287988062670977,
      "grad_norm": 0.6246493458747864,
      "learning_rate": 1.1866865622150378e-05,
      "loss": 5.254,
      "step": 18400
    },
    {
      "epoch": 2.3004227804028847,
      "grad_norm": 0.5149305462837219,
      "learning_rate": 1.1659620326618587e-05,
      "loss": 5.3752,
      "step": 18500
    },
    {
      "epoch": 2.3128574981347922,
      "grad_norm": 0.5974267721176147,
      "learning_rate": 1.1452375031086796e-05,
      "loss": 5.285,
      "step": 18600
    },
    {
      "epoch": 2.3252922158666998,
      "grad_norm": 0.6606773138046265,
      "learning_rate": 1.1245129735555003e-05,
      "loss": 5.3683,
      "step": 18700
    },
    {
      "epoch": 2.3377269335986073,
      "grad_norm": 0.9321348667144775,
      "learning_rate": 1.1037884440023212e-05,
      "loss": 5.3221,
      "step": 18800
    },
    {
      "epoch": 2.350161651330515,
      "grad_norm": 0.5004457831382751,
      "learning_rate": 1.0830639144491421e-05,
      "loss": 5.3229,
      "step": 18900
    },
    {
      "epoch": 2.3625963690624223,
      "grad_norm": 0.7015459537506104,
      "learning_rate": 1.0623393848959629e-05,
      "loss": 5.1986,
      "step": 19000
    },
    {
      "epoch": 2.37503108679433,
      "grad_norm": 0.7629091143608093,
      "learning_rate": 1.0416148553427838e-05,
      "loss": 5.3558,
      "step": 19100
    },
    {
      "epoch": 2.3874658045262374,
      "grad_norm": 0.4980051517486572,
      "learning_rate": 1.0208903257896047e-05,
      "loss": 5.3292,
      "step": 19200
    },
    {
      "epoch": 2.399900522258145,
      "grad_norm": 1.0977749824523926,
      "learning_rate": 1.0001657962364256e-05,
      "loss": 5.2581,
      "step": 19300
    },
    {
      "epoch": 2.4123352399900524,
      "grad_norm": 1.4330898523330688,
      "learning_rate": 9.794412666832463e-06,
      "loss": 5.3774,
      "step": 19400
    },
    {
      "epoch": 2.42476995772196,
      "grad_norm": 0.9047525525093079,
      "learning_rate": 9.587167371300672e-06,
      "loss": 5.3464,
      "step": 19500
    },
    {
      "epoch": 2.4372046754538674,
      "grad_norm": 1.2135791778564453,
      "learning_rate": 9.379922075768881e-06,
      "loss": 5.3254,
      "step": 19600
    },
    {
      "epoch": 2.4496393931857745,
      "grad_norm": 0.883857250213623,
      "learning_rate": 9.17267678023709e-06,
      "loss": 5.2676,
      "step": 19700
    },
    {
      "epoch": 2.462074110917682,
      "grad_norm": 1.1968964338302612,
      "learning_rate": 8.965431484705297e-06,
      "loss": 5.3382,
      "step": 19800
    },
    {
      "epoch": 2.4745088286495895,
      "grad_norm": 0.6077193021774292,
      "learning_rate": 8.758186189173506e-06,
      "loss": 5.3115,
      "step": 19900
    },
    {
      "epoch": 2.486943546381497,
      "grad_norm": 0.7923063039779663,
      "learning_rate": 8.550940893641715e-06,
      "loss": 5.3227,
      "step": 20000
    },
    {
      "epoch": 2.4993782641134046,
      "grad_norm": 0.6888896822929382,
      "learning_rate": 8.343695598109923e-06,
      "loss": 5.2688,
      "step": 20100
    },
    {
      "epoch": 2.511812981845312,
      "grad_norm": 1.064733624458313,
      "learning_rate": 8.136450302578132e-06,
      "loss": 5.293,
      "step": 20200
    },
    {
      "epoch": 2.5242476995772196,
      "grad_norm": 0.8028149604797363,
      "learning_rate": 7.92920500704634e-06,
      "loss": 5.349,
      "step": 20300
    },
    {
      "epoch": 2.536682417309127,
      "grad_norm": 0.6006583571434021,
      "learning_rate": 7.72195971151455e-06,
      "loss": 5.3066,
      "step": 20400
    },
    {
      "epoch": 2.5491171350410347,
      "grad_norm": 0.9211929440498352,
      "learning_rate": 7.514714415982757e-06,
      "loss": 5.1966,
      "step": 20500
    },
    {
      "epoch": 2.561551852772942,
      "grad_norm": 0.9064154028892517,
      "learning_rate": 7.307469120450966e-06,
      "loss": 5.3506,
      "step": 20600
    },
    {
      "epoch": 2.5739865705048497,
      "grad_norm": 0.6987286806106567,
      "learning_rate": 7.100223824919175e-06,
      "loss": 5.2988,
      "step": 20700
    },
    {
      "epoch": 2.5864212882367568,
      "grad_norm": 1.568401575088501,
      "learning_rate": 6.892978529387384e-06,
      "loss": 5.3077,
      "step": 20800
    },
    {
      "epoch": 2.5988560059686643,
      "grad_norm": 0.5948720574378967,
      "learning_rate": 6.685733233855591e-06,
      "loss": 5.3052,
      "step": 20900
    },
    {
      "epoch": 2.611290723700572,
      "grad_norm": 0.7859375476837158,
      "learning_rate": 6.4784879383238e-06,
      "loss": 5.2447,
      "step": 21000
    },
    {
      "epoch": 2.6237254414324793,
      "grad_norm": 5.866316318511963,
      "learning_rate": 6.271242642792009e-06,
      "loss": 5.3196,
      "step": 21100
    },
    {
      "epoch": 2.636160159164387,
      "grad_norm": 0.7590357661247253,
      "learning_rate": 6.0639973472602175e-06,
      "loss": 5.3529,
      "step": 21200
    },
    {
      "epoch": 2.6485948768962944,
      "grad_norm": 1.3240407705307007,
      "learning_rate": 5.856752051728426e-06,
      "loss": 5.3532,
      "step": 21300
    },
    {
      "epoch": 2.661029594628202,
      "grad_norm": 0.9733463525772095,
      "learning_rate": 5.649506756196635e-06,
      "loss": 5.3206,
      "step": 21400
    },
    {
      "epoch": 2.6734643123601094,
      "grad_norm": 0.7563100457191467,
      "learning_rate": 5.442261460664843e-06,
      "loss": 5.35,
      "step": 21500
    },
    {
      "epoch": 2.685899030092017,
      "grad_norm": 0.5281227231025696,
      "learning_rate": 5.235016165133052e-06,
      "loss": 5.2829,
      "step": 21600
    },
    {
      "epoch": 2.6983337478239244,
      "grad_norm": 0.8976628184318542,
      "learning_rate": 5.02777086960126e-06,
      "loss": 5.2811,
      "step": 21700
    },
    {
      "epoch": 2.710768465555832,
      "grad_norm": 0.5413350462913513,
      "learning_rate": 4.820525574069469e-06,
      "loss": 5.2611,
      "step": 21800
    },
    {
      "epoch": 2.7232031832877395,
      "grad_norm": 0.47759729623794556,
      "learning_rate": 4.613280278537677e-06,
      "loss": 5.3076,
      "step": 21900
    },
    {
      "epoch": 2.735637901019647,
      "grad_norm": 1.0548561811447144,
      "learning_rate": 4.406034983005886e-06,
      "loss": 5.2241,
      "step": 22000
    },
    {
      "epoch": 2.7480726187515545,
      "grad_norm": 0.7191539406776428,
      "learning_rate": 4.198789687474094e-06,
      "loss": 5.2963,
      "step": 22100
    },
    {
      "epoch": 2.760507336483462,
      "grad_norm": 0.9352497458457947,
      "learning_rate": 3.9915443919423026e-06,
      "loss": 5.2798,
      "step": 22200
    },
    {
      "epoch": 2.7729420542153695,
      "grad_norm": 0.8112477660179138,
      "learning_rate": 3.7842990964105116e-06,
      "loss": 5.3168,
      "step": 22300
    },
    {
      "epoch": 2.785376771947277,
      "grad_norm": 2.346646785736084,
      "learning_rate": 3.5770538008787197e-06,
      "loss": 5.2343,
      "step": 22400
    },
    {
      "epoch": 2.797811489679184,
      "grad_norm": 0.4714936316013336,
      "learning_rate": 3.3698085053469288e-06,
      "loss": 5.3796,
      "step": 22500
    },
    {
      "epoch": 2.8102462074110917,
      "grad_norm": 0.7776939868927002,
      "learning_rate": 3.162563209815137e-06,
      "loss": 5.3213,
      "step": 22600
    },
    {
      "epoch": 2.822680925142999,
      "grad_norm": 0.5482866764068604,
      "learning_rate": 2.955317914283346e-06,
      "loss": 5.3452,
      "step": 22700
    },
    {
      "epoch": 2.8351156428749067,
      "grad_norm": 0.9448392391204834,
      "learning_rate": 2.748072618751554e-06,
      "loss": 5.4071,
      "step": 22800
    },
    {
      "epoch": 2.847550360606814,
      "grad_norm": 0.7776166796684265,
      "learning_rate": 2.5408273232197627e-06,
      "loss": 5.3834,
      "step": 22900
    },
    {
      "epoch": 2.8599850783387217,
      "grad_norm": 0.7487010955810547,
      "learning_rate": 2.3335820276879713e-06,
      "loss": 5.3961,
      "step": 23000
    },
    {
      "epoch": 2.8724197960706292,
      "grad_norm": 2.1603455543518066,
      "learning_rate": 2.12633673215618e-06,
      "loss": 5.2598,
      "step": 23100
    },
    {
      "epoch": 2.8848545138025368,
      "grad_norm": 1.3538804054260254,
      "learning_rate": 1.9190914366243885e-06,
      "loss": 5.3783,
      "step": 23200
    },
    {
      "epoch": 2.8972892315344443,
      "grad_norm": 0.6625190377235413,
      "learning_rate": 1.7118461410925973e-06,
      "loss": 5.2542,
      "step": 23300
    },
    {
      "epoch": 2.909723949266352,
      "grad_norm": 0.6710235476493835,
      "learning_rate": 1.5046008455608059e-06,
      "loss": 5.4195,
      "step": 23400
    },
    {
      "epoch": 2.922158666998259,
      "grad_norm": 0.9218568205833435,
      "learning_rate": 1.2973555500290144e-06,
      "loss": 5.3141,
      "step": 23500
    },
    {
      "epoch": 2.9345933847301664,
      "grad_norm": 0.5383564233779907,
      "learning_rate": 1.090110254497223e-06,
      "loss": 5.3858,
      "step": 23600
    },
    {
      "epoch": 2.947028102462074,
      "grad_norm": 0.84101402759552,
      "learning_rate": 8.828649589654314e-07,
      "loss": 5.2766,
      "step": 23700
    },
    {
      "epoch": 2.9594628201939814,
      "grad_norm": 1.0362719297409058,
      "learning_rate": 6.7561966343364e-07,
      "loss": 5.2642,
      "step": 23800
    },
    {
      "epoch": 2.971897537925889,
      "grad_norm": 1.078391432762146,
      "learning_rate": 4.6837436790184865e-07,
      "loss": 5.3107,
      "step": 23900
    },
    {
      "epoch": 2.9843322556577965,
      "grad_norm": 0.5590648651123047,
      "learning_rate": 2.6112907237005724e-07,
      "loss": 5.2993,
      "step": 24000
    }
  ],
  "logging_steps": 100,
  "max_steps": 24126,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.047102608029778e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
