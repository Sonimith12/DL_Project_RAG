{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_drug = pd.read_csv('dataset/train.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>name_of_drug</th>\n",
       "      <th>use_case_for_drug</th>\n",
       "      <th>review_by_patient</th>\n",
       "      <th>effectiveness_rating</th>\n",
       "      <th>drug_approved_by_UIC</th>\n",
       "      <th>number_of_times_prescribed</th>\n",
       "      <th>base_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "      <td>8.022969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "      <td>7.858458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "      <td>6.341969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9</td>\n",
       "      <td>27-Nov-16</td>\n",
       "      <td>37</td>\n",
       "      <td>6.590176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155963</td>\n",
       "      <td>Cialis</td>\n",
       "      <td>Benign Prostatic Hyperplasia</td>\n",
       "      <td>\"2nd day on 5mg started to work with rock hard...</td>\n",
       "      <td>2</td>\n",
       "      <td>28-Nov-15</td>\n",
       "      <td>43</td>\n",
       "      <td>6.144782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32160</th>\n",
       "      <td>183202</td>\n",
       "      <td>Cymbalta</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>\"I have been taking Cymbalta for 15 months now...</td>\n",
       "      <td>9</td>\n",
       "      <td>10-Jun-13</td>\n",
       "      <td>89</td>\n",
       "      <td>6.963020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32161</th>\n",
       "      <td>109111</td>\n",
       "      <td>Nexplanon</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I have had the Nexplanon since Dec. 27, 2016 ...</td>\n",
       "      <td>6</td>\n",
       "      <td>6-Apr-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32162</th>\n",
       "      <td>121154</td>\n",
       "      <td>Venlafaxine</td>\n",
       "      <td>Panic Disorde</td>\n",
       "      <td>\"Had panic attacks and social anxiety starting...</td>\n",
       "      <td>9</td>\n",
       "      <td>10-Nov-16</td>\n",
       "      <td>25</td>\n",
       "      <td>6.241812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32163</th>\n",
       "      <td>45410</td>\n",
       "      <td>Fluoxetine</td>\n",
       "      <td>Obsessive Compulsive Disorde</td>\n",
       "      <td>\"I have been off Prozac for about 4 weeks now....</td>\n",
       "      <td>8</td>\n",
       "      <td>21-Jan-15</td>\n",
       "      <td>22</td>\n",
       "      <td>7.940428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32164</th>\n",
       "      <td>187382</td>\n",
       "      <td>Orencia</td>\n",
       "      <td>Rheumatoid Arthritis</td>\n",
       "      <td>\"Limited improvement after 4 months, developed...</td>\n",
       "      <td>2</td>\n",
       "      <td>15-Mar-14</td>\n",
       "      <td>35</td>\n",
       "      <td>8.205393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32165 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       patient_id              name_of_drug             use_case_for_drug  \\\n",
       "0          206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1           95260                Guanfacine                          ADHD   \n",
       "2           92703                    Lybrel                 Birth Control   \n",
       "3           35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "4          155963                    Cialis  Benign Prostatic Hyperplasia   \n",
       "...           ...                       ...                           ...   \n",
       "32160      183202                  Cymbalta                       Anxiety   \n",
       "32161      109111                 Nexplanon                 Birth Control   \n",
       "32162      121154               Venlafaxine                 Panic Disorde   \n",
       "32163       45410                Fluoxetine  Obsessive Compulsive Disorde   \n",
       "32164      187382                   Orencia          Rheumatoid Arthritis   \n",
       "\n",
       "                                       review_by_patient  \\\n",
       "0      \"It has no side effect, I take it in combinati...   \n",
       "1      \"My son is halfway through his fourth week of ...   \n",
       "2      \"I used to take another oral contraceptive, wh...   \n",
       "3      \"Suboxone has completely turned my life around...   \n",
       "4      \"2nd day on 5mg started to work with rock hard...   \n",
       "...                                                  ...   \n",
       "32160  \"I have been taking Cymbalta for 15 months now...   \n",
       "32161  \"I have had the Nexplanon since Dec. 27, 2016 ...   \n",
       "32162  \"Had panic attacks and social anxiety starting...   \n",
       "32163  \"I have been off Prozac for about 4 weeks now....   \n",
       "32164  \"Limited improvement after 4 months, developed...   \n",
       "\n",
       "       effectiveness_rating drug_approved_by_UIC  number_of_times_prescribed  \\\n",
       "0                         9            20-May-12                          27   \n",
       "1                         8            27-Apr-10                         192   \n",
       "2                         5            14-Dec-09                          17   \n",
       "3                         9            27-Nov-16                          37   \n",
       "4                         2            28-Nov-15                          43   \n",
       "...                     ...                  ...                         ...   \n",
       "32160                     9            10-Jun-13                          89   \n",
       "32161                     6             6-Apr-17                           0   \n",
       "32162                     9            10-Nov-16                          25   \n",
       "32163                     8            21-Jan-15                          22   \n",
       "32164                     2            15-Mar-14                          35   \n",
       "\n",
       "       base_score  \n",
       "0        8.022969  \n",
       "1        7.858458  \n",
       "2        6.341969  \n",
       "3        6.590176  \n",
       "4        6.144782  \n",
       "...           ...  \n",
       "32160    6.963020  \n",
       "32161    0.899076  \n",
       "32162    6.241812  \n",
       "32163    7.940428  \n",
       "32164    8.205393  \n",
       "\n",
       "[32165 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_id', 'name_of_drug', 'use_case_for_drug', 'review_by_patient',\n",
       "       'effectiveness_rating', 'drug_approved_by_UIC',\n",
       "       'number_of_times_prescribed', 'base_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drug.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_of_drug</th>\n",
       "      <th>use_case_for_drug</th>\n",
       "      <th>review_by_patient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cialis</td>\n",
       "      <td>Benign Prostatic Hyperplasia</td>\n",
       "      <td>\"2nd day on 5mg started to work with rock hard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32160</th>\n",
       "      <td>Cymbalta</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>\"I have been taking Cymbalta for 15 months now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32161</th>\n",
       "      <td>Nexplanon</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I have had the Nexplanon since Dec. 27, 2016 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32162</th>\n",
       "      <td>Venlafaxine</td>\n",
       "      <td>Panic Disorde</td>\n",
       "      <td>\"Had panic attacks and social anxiety starting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32163</th>\n",
       "      <td>Fluoxetine</td>\n",
       "      <td>Obsessive Compulsive Disorde</td>\n",
       "      <td>\"I have been off Prozac for about 4 weeks now....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32164</th>\n",
       "      <td>Orencia</td>\n",
       "      <td>Rheumatoid Arthritis</td>\n",
       "      <td>\"Limited improvement after 4 months, developed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32165 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name_of_drug             use_case_for_drug  \\\n",
       "0                     Valsartan  Left Ventricular Dysfunction   \n",
       "1                    Guanfacine                          ADHD   \n",
       "2                        Lybrel                 Birth Control   \n",
       "3      Buprenorphine / naloxone             Opiate Dependence   \n",
       "4                        Cialis  Benign Prostatic Hyperplasia   \n",
       "...                         ...                           ...   \n",
       "32160                  Cymbalta                       Anxiety   \n",
       "32161                 Nexplanon                 Birth Control   \n",
       "32162               Venlafaxine                 Panic Disorde   \n",
       "32163                Fluoxetine  Obsessive Compulsive Disorde   \n",
       "32164                   Orencia          Rheumatoid Arthritis   \n",
       "\n",
       "                                       review_by_patient  \n",
       "0      \"It has no side effect, I take it in combinati...  \n",
       "1      \"My son is halfway through his fourth week of ...  \n",
       "2      \"I used to take another oral contraceptive, wh...  \n",
       "3      \"Suboxone has completely turned my life around...  \n",
       "4      \"2nd day on 5mg started to work with rock hard...  \n",
       "...                                                  ...  \n",
       "32160  \"I have been taking Cymbalta for 15 months now...  \n",
       "32161  \"I have had the Nexplanon since Dec. 27, 2016 ...  \n",
       "32162  \"Had panic attacks and social anxiety starting...  \n",
       "32163  \"I have been off Prozac for about 4 weeks now....  \n",
       "32164  \"Limited improvement after 4 months, developed...  \n",
       "\n",
       "[32165 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drug.drop(['drug_approved_by_UIC','number_of_times_prescribed','base_score','effectiveness_rating','patient_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the columns into a single text column called 'combined_text'\n",
    "df_drug['combined_text'] = df_drug.apply(\n",
    "    lambda x: f\"Drug: {x['name_of_drug']} | Use Case: {x['use_case_for_drug']} | Review: {x['review_by_patient']}\",\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte avec le moins de caractères : Drug: Vitapap | Use Case: Pain | Review: \"Good\" (47 caractères)\n",
      "Texte avec le plus de caractères : Drug: Acetaminophen / aspirin / caffeine | Use Case: Migraine | Review: \"Like all medications I&#039;ve ever taken, I followed the directions exactly (&quot;take 2 caplets with a glass of water&quot;) and the product worked great, with no side effects. With regard to those complaining that the product was ineffective or gave you bad side effects, PLEASE read the following. Although Excedrin Migraine and Excedrin Extra Strength are the exact same product, it is vitally important to follow the Excedrin Migraine directions if you are taking the pills for a migraine, NOT the directions for Extra Strength Excedrin! Here&#039;s why. Many people have incorrectly assumed that because the two products are exactly the same, which they indeed are, that the directions are also the same. THIS IS COMPLETELY FALSE. The reason that there is a separate product solely for migraines, and the FDA approved it solely for migraine use only, is because the amount you take for migraines is completely different than for general pain relief, including &quot;regular&quot; headaches. The reason Excedrin Migraine instructs you to take only 2 pills in 24 hours (vs 8 pills in 24 hours for Extra Strength Excedrin) is because taking more than 2 pills in 24 hours (for a migraine) is likely to cause rebound migraines for many people. In other words, taking more pills than the directions tell you to will make your migraine problem worse! You will note on the Excedrin Migraine package that the ONLY use for the product is &quot;treats migraines.&quot; Think about that! The directions match that one usage and this is the reason the FDA approved the product. So if you have migraines and want to buy Extra Strength Excedrin, instead of Excedrin Migraine, that&#039;s totally fine, but be sure to follow the Excedrin Migraine directions! If you&#039;re taking the product for migraines and you take more than 2 pills in 24 hours, you can definitely except to experience the bad side effects that many people have talked about on this site! And keep in mind that although you should NEVER take more than 2 pills in 24 hours (if your using it for migraines), that doesn&#039;t mean you can&#039;t take just 1 pill in 24 hours. For some people, just 1 pill will get rid of your migraine. If 1 pill isn&#039;t working for you, then you can always take another one during each 24 hours. So less is fine, but more is a huge mistake. I hope I&#039;ve made my point. Review sites in general tend to attract people who have bad things to say about a product. People who have a good experience with a product are much less likely to post their comments on a site like this. Why? Because angry people want to vent. This is not to say that some people who complain are insincere or haven&#039;t followed the directions of the product. There are always going to be people who a product just doesn&#039;t work for. But most people who properly follow the directions will not have bad results. Also, for migraines specifically, finding a product that truly gets rid of them can be very difficult for many people. It&#039;s trial and error. If one product doesn&#039;t work, you try another until you hopefully find one that does the trick. So a product not getting rid of your migraines is one thing, but having painful or uncomfortable side effects is another. Follow the directions and you most likely will never have the bad side effects. Whether it works to get rid of your migraine is a coin toss, but at least you won&#039;t have the bad side effects in most cases. I hope this helped. Good luck to all migraine sufferers. I know how awful they are.\" (3627 caractères)\n"
     ]
    }
   ],
   "source": [
    "# Texte avec le nombre minimum de caractères\n",
    "min_text = df_drug.loc[df_drug['combined_text'].apply(len).idxmin(), 'combined_text']\n",
    "\n",
    "# Texte avec le nombre maximum de caractères\n",
    "max_text = df_drug.loc[df_drug['combined_text'].apply(len).idxmax(), 'combined_text']\n",
    "\n",
    "# Afficher les longueurs\n",
    "min_len = len(min_text)\n",
    "max_len = len(max_text)\n",
    "\n",
    "print(f\"Texte avec le moins de caractères : {min_text} ({min_len} caractères)\")\n",
    "print(f\"Texte avec le plus de caractères : {max_text} ({max_len} caractères)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de textes avec plus de 2000 caractères : 10\n"
     ]
    }
   ],
   "source": [
    "# Compter le nombre de textes avec plus de 2000 caractères\n",
    "count_above_2000 = df_drug['combined_text'].apply(len).gt(2000).sum()\n",
    "\n",
    "print(f\"Nombre de textes avec plus de 2000 caractères : {count_above_2000}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de textes qui dépassent la limite pour multi-qa-mpnet-base-dot-v1: 9\n",
      "Nombre de textes qui dépassent la limite pour all-MiniLM-L6-v2: 27\n",
      "Nombre de textes qui dépassent la limite pour all-MiniLM-L12-v1: 27\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Modèles et leurs limites\n",
    "models = {\n",
    "    \"multi-qa-mpnet-base-dot-v1\": {\"tokenizer\": AutoTokenizer.from_pretrained(\"sentence-transformers/multi-qa-mpnet-base-dot-v1\"), \"max_tokens\": 512},\n",
    "    \"all-MiniLM-L6-v2\": {\"tokenizer\": AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"), \"max_tokens\": 384},\n",
    "    \"all-MiniLM-L12-v1\": {\"tokenizer\": AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L12-v1\"), \"max_tokens\": 384},\n",
    "}\n",
    "\n",
    "# Calculer combien de textes dépassent la limite pour chaque modèle\n",
    "exceeds_limit = {}\n",
    "for model_name, data in models.items():\n",
    "    tokenizer = data[\"tokenizer\"]\n",
    "    max_tokens = data[\"max_tokens\"]\n",
    "    \n",
    "    # Calculer le nombre de tokens pour chaque texte\n",
    "    df_drug[f\"{model_name}_token_count\"] = df_drug['combined_text'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "    \n",
    "    # Vérifier les textes qui dépassent la limite\n",
    "    exceeds_limit[model_name] = (df_drug[f\"{model_name}_token_count\"] > max_tokens).sum()\n",
    "\n",
    "# Afficher les résultats\n",
    "for model_name, count in exceeds_limit.items():\n",
    "    print(f\"Nombre de textes qui dépassent la limite pour {model_name}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "657"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max(df_drug['combined_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>name_of_drug</th>\n",
       "      <th>use_case_for_drug</th>\n",
       "      <th>review_by_patient</th>\n",
       "      <th>effectiveness_rating</th>\n",
       "      <th>drug_approved_by_UIC</th>\n",
       "      <th>number_of_times_prescribed</th>\n",
       "      <th>base_score</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "      <td>8.022969</td>\n",
       "      <td>Drug: Valsartan | Use Case: Left Ventricular D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "      <td>7.858458</td>\n",
       "      <td>Drug: Guanfacine | Use Case: ADHD | Review: \"M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "      <td>6.341969</td>\n",
       "      <td>Drug: Lybrel | Use Case: Birth Control | Revie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9</td>\n",
       "      <td>27-Nov-16</td>\n",
       "      <td>37</td>\n",
       "      <td>6.590176</td>\n",
       "      <td>Drug: Buprenorphine / naloxone | Use Case: Opi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155963</td>\n",
       "      <td>Cialis</td>\n",
       "      <td>Benign Prostatic Hyperplasia</td>\n",
       "      <td>\"2nd day on 5mg started to work with rock hard...</td>\n",
       "      <td>2</td>\n",
       "      <td>28-Nov-15</td>\n",
       "      <td>43</td>\n",
       "      <td>6.144782</td>\n",
       "      <td>Drug: Cialis | Use Case: Benign Prostatic Hype...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32160</th>\n",
       "      <td>183202</td>\n",
       "      <td>Cymbalta</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>\"I have been taking Cymbalta for 15 months now...</td>\n",
       "      <td>9</td>\n",
       "      <td>10-Jun-13</td>\n",
       "      <td>89</td>\n",
       "      <td>6.963020</td>\n",
       "      <td>Drug: Cymbalta | Use Case: Anxiety | Review: \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32161</th>\n",
       "      <td>109111</td>\n",
       "      <td>Nexplanon</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I have had the Nexplanon since Dec. 27, 2016 ...</td>\n",
       "      <td>6</td>\n",
       "      <td>6-Apr-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899076</td>\n",
       "      <td>Drug: Nexplanon | Use Case: Birth Control | Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32162</th>\n",
       "      <td>121154</td>\n",
       "      <td>Venlafaxine</td>\n",
       "      <td>Panic Disorde</td>\n",
       "      <td>\"Had panic attacks and social anxiety starting...</td>\n",
       "      <td>9</td>\n",
       "      <td>10-Nov-16</td>\n",
       "      <td>25</td>\n",
       "      <td>6.241812</td>\n",
       "      <td>Drug: Venlafaxine | Use Case: Panic Disorde | ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32163</th>\n",
       "      <td>45410</td>\n",
       "      <td>Fluoxetine</td>\n",
       "      <td>Obsessive Compulsive Disorde</td>\n",
       "      <td>\"I have been off Prozac for about 4 weeks now....</td>\n",
       "      <td>8</td>\n",
       "      <td>21-Jan-15</td>\n",
       "      <td>22</td>\n",
       "      <td>7.940428</td>\n",
       "      <td>Drug: Fluoxetine | Use Case: Obsessive Compuls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32164</th>\n",
       "      <td>187382</td>\n",
       "      <td>Orencia</td>\n",
       "      <td>Rheumatoid Arthritis</td>\n",
       "      <td>\"Limited improvement after 4 months, developed...</td>\n",
       "      <td>2</td>\n",
       "      <td>15-Mar-14</td>\n",
       "      <td>35</td>\n",
       "      <td>8.205393</td>\n",
       "      <td>Drug: Orencia | Use Case: Rheumatoid Arthritis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32165 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       patient_id              name_of_drug             use_case_for_drug  \\\n",
       "0          206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1           95260                Guanfacine                          ADHD   \n",
       "2           92703                    Lybrel                 Birth Control   \n",
       "3           35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "4          155963                    Cialis  Benign Prostatic Hyperplasia   \n",
       "...           ...                       ...                           ...   \n",
       "32160      183202                  Cymbalta                       Anxiety   \n",
       "32161      109111                 Nexplanon                 Birth Control   \n",
       "32162      121154               Venlafaxine                 Panic Disorde   \n",
       "32163       45410                Fluoxetine  Obsessive Compulsive Disorde   \n",
       "32164      187382                   Orencia          Rheumatoid Arthritis   \n",
       "\n",
       "                                       review_by_patient  \\\n",
       "0      \"It has no side effect, I take it in combinati...   \n",
       "1      \"My son is halfway through his fourth week of ...   \n",
       "2      \"I used to take another oral contraceptive, wh...   \n",
       "3      \"Suboxone has completely turned my life around...   \n",
       "4      \"2nd day on 5mg started to work with rock hard...   \n",
       "...                                                  ...   \n",
       "32160  \"I have been taking Cymbalta for 15 months now...   \n",
       "32161  \"I have had the Nexplanon since Dec. 27, 2016 ...   \n",
       "32162  \"Had panic attacks and social anxiety starting...   \n",
       "32163  \"I have been off Prozac for about 4 weeks now....   \n",
       "32164  \"Limited improvement after 4 months, developed...   \n",
       "\n",
       "       effectiveness_rating drug_approved_by_UIC  number_of_times_prescribed  \\\n",
       "0                         9            20-May-12                          27   \n",
       "1                         8            27-Apr-10                         192   \n",
       "2                         5            14-Dec-09                          17   \n",
       "3                         9            27-Nov-16                          37   \n",
       "4                         2            28-Nov-15                          43   \n",
       "...                     ...                  ...                         ...   \n",
       "32160                     9            10-Jun-13                          89   \n",
       "32161                     6             6-Apr-17                           0   \n",
       "32162                     9            10-Nov-16                          25   \n",
       "32163                     8            21-Jan-15                          22   \n",
       "32164                     2            15-Mar-14                          35   \n",
       "\n",
       "       base_score                                      combined_text  \n",
       "0        8.022969  Drug: Valsartan | Use Case: Left Ventricular D...  \n",
       "1        7.858458  Drug: Guanfacine | Use Case: ADHD | Review: \"M...  \n",
       "2        6.341969  Drug: Lybrel | Use Case: Birth Control | Revie...  \n",
       "3        6.590176  Drug: Buprenorphine / naloxone | Use Case: Opi...  \n",
       "4        6.144782  Drug: Cialis | Use Case: Benign Prostatic Hype...  \n",
       "...           ...                                                ...  \n",
       "32160    6.963020  Drug: Cymbalta | Use Case: Anxiety | Review: \"...  \n",
       "32161    0.899076  Drug: Nexplanon | Use Case: Birth Control | Re...  \n",
       "32162    6.241812  Drug: Venlafaxine | Use Case: Panic Disorde | ...  \n",
       "32163    7.940428  Drug: Fluoxetine | Use Case: Obsessive Compuls...  \n",
       "32164    8.205393  Drug: Orencia | Use Case: Rheumatoid Arthritis...  \n",
       "\n",
       "[32165 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Les embeddings existent déjà dans ChromaDB.\n",
      "Les questions et réponses ont été sauvegardées dans comparaisonLLMemb/results_all-MiniLM-L6-v2_gemini-1_5-flash.json.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import torch\n",
    "import time\n",
    "import random \n",
    "import os\n",
    "\n",
    "# Lire la clé API depuis API.txt\n",
    "with open(\"API.txt\", \"r\") as file:\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "# Configurer l'API Gemini avec la clé\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialisez l'instance de ChromaDB (Vector Store)\n",
    "\n",
    "db_path = \"chroma_db\"\n",
    "if not os.path.exists(db_path):\n",
    "    os.makedirs(db_path)\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=db_path)\n",
    "collection = chroma_client.get_or_create_collection(name=\"drug_embeddings\")\n",
    "\n",
    "# Charger le modèle d'embedding\n",
    "embedding_model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "embedding_model = SentenceTransformer(embedding_model_name)\n",
    "embedding_model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def add_embeddings_to_vectorstore(df):\n",
    "    # Vérifiez si la collection est vide en utilisant une autre méthode\n",
    "    if collection.count() == 0:  # Vérifie le nombre total de documents dans la collection\n",
    "        for index, row in df.iterrows():\n",
    "            embedding = embedding_model.encode(row['combined_text'], device=device).tolist()\n",
    "            collection.add(\n",
    "                documents=[row['combined_text']],\n",
    "                embeddings=[embedding],\n",
    "                ids=[str(index)]\n",
    "            )\n",
    "        print(\"Embeddings ajoutés à ChromaDB.\")\n",
    "    else:\n",
    "        print(\"Les embeddings existent déjà dans ChromaDB.\")\n",
    "\n",
    "# Ajoutez vos données existantes\n",
    "add_embeddings_to_vectorstore(df_drug)\n",
    "\n",
    "# Fonction pour utiliser le modèle Gemini\n",
    "def query_gemini_with_retry(prompt, model_name=\"gemini-1.5-flash\", retries=1):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            model = genai.GenerativeModel(model_name)\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(2 ** attempt + random.random())  # Exponential backoff\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "# Fonction RAG pour répondre aux questions\n",
    "def rag_pipeline(query, results_number=10, llm_model_name=\"gemini-1.5-flash\"):\n",
    "    # Générer l'embedding de la requête\n",
    "    query_embedding = embedding_model.encode(query).tolist()\n",
    "    \n",
    "    # Rechercher les contextes pertinents dans ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=results_number\n",
    "    )\n",
    "    \n",
    "    # Construire le contexte pour le modèle LLM\n",
    "    contexts = results[\"documents\"][0]\n",
    "    context_text = \"\\n\".join([f\"Context {i + 1}: {text}\" for i, text in enumerate(contexts)])\n",
    "    input_prompt = f\"\"\"\n",
    "It's a school project. You are an AI assistant tasked with answering questions using only the information in the provided context. Do not add any extra information or assumptions.\n",
    "\n",
    "Context:\n",
    "{context_text}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Instructions:\n",
    "1. Use only the information in the context to answer the question.\n",
    "2. If the context mentions multiple options, provide a list of those options clearly.\n",
    "3. If the context does not provide relevant information, state: \"The context does not contain enough information to answer this question.\"\n",
    "4. Do not include any policy or ethical reasoning in your response.\n",
    "5. Dont quote the Context and dont mention that you used a context/reviews to answer\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    # Générer une réponse à l'aide de Gemini\n",
    "    response = query_gemini_with_retry(input_prompt, model_name=llm_model_name)\n",
    "    return response\n",
    "\n",
    "# Charger les questions depuis le fichier JSON\n",
    "with open(\"questions.json\", \"r\") as file:\n",
    "    questions_data = json.load(file)\n",
    "\n",
    "# Stocker les résultats\n",
    "results = {\n",
    "    \"meta\": {\n",
    "        \"embedding_model\": embedding_model_name,\n",
    "        \"llm_model\": \"gemini-1.5-flash\",\n",
    "        \"results_number\": 10\n",
    "    },\n",
    "    \"qa_pairs\": []\n",
    "}\n",
    "\n",
    "# Limiter à 10 premières questions\n",
    "questions_subset = questions_data\n",
    "\n",
    "# Itérer sur les 10 premières questions et collecter les réponses\n",
    "for question_obj in questions_subset:\n",
    "    question = question_obj[\"question\"]\n",
    "    answer = rag_pipeline(question)\n",
    "    results[\"qa_pairs\"].append({\"question\": question, \"answer\": answer})\n",
    "    time.sleep(10)  # Petite pause entre les appels pour éviter les dépassements de quota\n",
    "\n",
    "# Définir le répertoire ou fichier cible pour sauvegarder les résultats\n",
    "output_directory = \"comparaisonLLMemb\"\n",
    "os.makedirs(output_directory, exist_ok=True)  # Crée le répertoire s'il n'existe pas\n",
    "\n",
    "# Générer un nom de fichier dynamique\n",
    "output_filename = os.path.join(\n",
    "    output_directory, \n",
    "    f\"results_{embedding_model_name.split('/')[-1]}_{results['meta']['llm_model'].replace('.', '_')}.json\"\n",
    ")\n",
    "\n",
    "# Sauvegarder les résultats dans un fichier JSON\n",
    "with open(output_filename, \"w\") as output_file:\n",
    "    json.dump(results, output_file, indent=4)\n",
    "\n",
    "print(f\"Les questions et réponses ont été sauvegardées dans {output_filename}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Les embeddings existent déjà dans ChromaDB.\n",
      "Les questions et réponses ont été sauvegardées dans comparaisonLLMemb/results_all-MiniLM-L12-v1_gemini-1_5-flash.json.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Lire la clé API depuis API.txt\n",
    "with open(\"API.txt\", \"r\") as file:\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "# Configurer l'API Gemini avec la clé\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialisez l'instance de ChromaDB (Vector Store)\n",
    "db_path = \"chroma_db_gem_miniL12\"\n",
    "if not os.path.exists(db_path):\n",
    "    os.makedirs(db_path)\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=db_path)\n",
    "collection = chroma_client.get_or_create_collection(name=\"drug_embeddings\")\n",
    "\n",
    "# Charger le modèle d'embedding\n",
    "embedding_model_name = 'sentence-transformers/all-MiniLM-L12-v1'\n",
    "embedding_model = SentenceTransformer(embedding_model_name)\n",
    "embedding_model.to(device)\n",
    "\n",
    "def add_embeddings_to_vectorstore(df):\n",
    "    if collection.count() == 0:  # Vérifie le nombre total de documents dans la collection\n",
    "        for index, row in df.iterrows():\n",
    "            embedding = embedding_model.encode(row['combined_text'], device=device).tolist()\n",
    "            collection.add(\n",
    "                documents=[row['combined_text']],\n",
    "                embeddings=[embedding],\n",
    "                ids=[str(index)]\n",
    "            )\n",
    "        print(\"Embeddings ajoutés à ChromaDB.\")\n",
    "    else:\n",
    "        print(\"Les embeddings existent déjà dans ChromaDB.\")\n",
    "\n",
    "# Ajoutez vos données existantes\n",
    "add_embeddings_to_vectorstore(df_drug)\n",
    "\n",
    "# Fonction pour utiliser le modèle Gemini\n",
    "def query_gemini_with_retry(prompt, model_name=\"gemini-1.5-flash\", retries=1):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            model = genai.GenerativeModel(model_name)\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(2 ** attempt + random.random())  # Exponential backoff\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "# Fonction RAG pour répondre aux questions\n",
    "def rag_pipeline(query, results_number=10, llm_model_name=\"gemini-1.5-flash\"):\n",
    "    # Générer l'embedding de la requête\n",
    "    query_embedding = embedding_model.encode(query).tolist()\n",
    "    \n",
    "    # Rechercher les contextes pertinents dans ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=results_number\n",
    "    )\n",
    "    \n",
    "    # Construire le contexte pour le modèle LLM\n",
    "    contexts = results[\"documents\"][0]\n",
    "    context_text = \"\\n\".join([f\"Context {i + 1}: {text}\" for i, text in enumerate(contexts)])\n",
    "    input_prompt = f\"\"\"\n",
    "It's a school project. You are an AI assistant tasked with answering questions using only the information in the provided context. Do not add any extra information or assumptions.\n",
    "\n",
    "Context:\n",
    "{context_text}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Instructions:\n",
    "1. Use only the information in the context to answer the question.\n",
    "2. If the context mentions multiple options, provide a list of those options clearly.\n",
    "3. If the context does not provide relevant information, state: \"The context does not contain enough information to answer this question.\"\n",
    "4. Do not include any policy or ethical reasoning in your response.\n",
    "5. Dont quote the Context and dont mention that you used a context/reviews to answer\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    # Générer une réponse à l'aide de Gemini\n",
    "    response = query_gemini_with_retry(input_prompt, model_name=llm_model_name)\n",
    "    return response\n",
    "\n",
    "# Charger les questions depuis le fichier JSON\n",
    "with open(\"questions.json\", \"r\") as file:\n",
    "    questions_data = json.load(file)\n",
    "\n",
    "# Stocker les résultats\n",
    "results = {\n",
    "    \"meta\": {\n",
    "        \"embedding_model\": embedding_model_name,\n",
    "        \"llm_model\": \"gemini-1.5-flash\",\n",
    "        \"results_number\": 10\n",
    "    },\n",
    "    \"qa_pairs\": []\n",
    "}\n",
    "\n",
    "# Limiter à 10 premières questions\n",
    "questions_subset = questions_data\n",
    "\n",
    "# Itérer sur les 10 premières questions et collecter les réponses\n",
    "for question_obj in questions_subset:\n",
    "    question = question_obj[\"question\"]\n",
    "    answer = rag_pipeline(question)\n",
    "    results[\"qa_pairs\"].append({\"question\": question, \"answer\": answer})\n",
    "    time.sleep(10)  # Petite pause entre les appels pour éviter les dépassements de quota\n",
    "\n",
    "# Définir le répertoire ou fichier cible pour sauvegarder les résultats\n",
    "output_directory = \"comparaisonLLMemb\"\n",
    "os.makedirs(output_directory, exist_ok=True)  # Crée le répertoire s'il n'existe pas\n",
    "\n",
    "# Générer un nom de fichier dynamique\n",
    "output_filename = os.path.join(\n",
    "    output_directory, \n",
    "    f\"results_{embedding_model_name.split('/')[-1]}_{results['meta']['llm_model'].replace('.', '_')}.json\"\n",
    ")\n",
    "\n",
    "# Sauvegarder les résultats dans un fichier JSON\n",
    "with open(output_filename, \"w\") as output_file:\n",
    "    json.dump(results, output_file, indent=4)\n",
    "\n",
    "print(f\"Les questions et réponses ont été sauvegardées dans {output_filename}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Embeddings ajoutés à ChromaDB.\n",
      "Les questions et réponses ont été sauvegardées dans comparaisonLLMemb/results_multi-qa-mpnet-base-dot-v1_gemini-1_5-flash.json.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Lire la clé API depuis API.txt\n",
    "with open(\"API.txt\", \"r\") as file:\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "# Configurer l'API Gemini avec la clé\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialisez l'instance de ChromaDB (Vector Store)\n",
    "db_path = \"chroma_db_gem_mpnet\"\n",
    "if not os.path.exists(db_path):\n",
    "    os.makedirs(db_path)\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=db_path)\n",
    "collection = chroma_client.get_or_create_collection(name=\"drug_embeddings\")\n",
    "\n",
    "# Charger le modèle d'embedding\n",
    "embedding_model_name = 'sentence-transformers/multi-qa-mpnet-base-dot-v1'\n",
    "embedding_model = SentenceTransformer(embedding_model_name)\n",
    "embedding_model.to(device)\n",
    "\n",
    "def add_embeddings_to_vectorstore(df):\n",
    "    if collection.count() == 0:  # Vérifie le nombre total de documents dans la collection\n",
    "        for index, row in df.iterrows():\n",
    "            embedding = embedding_model.encode(row['combined_text'], device=device).tolist()\n",
    "            collection.add(\n",
    "                documents=[row['combined_text']],\n",
    "                embeddings=[embedding],\n",
    "                ids=[str(index)]\n",
    "            )\n",
    "        print(\"Embeddings ajoutés à ChromaDB.\")\n",
    "    else:\n",
    "        print(\"Les embeddings existent déjà dans ChromaDB.\")\n",
    "\n",
    "# Ajoutez vos données existantes\n",
    "add_embeddings_to_vectorstore(df_drug)\n",
    "\n",
    "# Fonction pour utiliser le modèle Gemini\n",
    "def query_gemini_with_retry(prompt, model_name=\"gemini-1.5-flash\", retries=1):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            model = genai.GenerativeModel(model_name)\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(2 ** attempt + random.random())  # Exponential backoff\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "# Fonction RAG pour répondre aux questions\n",
    "def rag_pipeline(query, results_number=10, llm_model_name=\"gemini-1.5-flash\"):\n",
    "    # Générer l'embedding de la requête\n",
    "    query_embedding = embedding_model.encode(query).tolist()\n",
    "    \n",
    "    # Rechercher les contextes pertinents dans ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=results_number\n",
    "    )\n",
    "    \n",
    "    # Construire le contexte pour le modèle LLM\n",
    "    contexts = results[\"documents\"][0]\n",
    "    context_text = \"\\n\".join([f\"Context {i + 1}: {text}\" for i, text in enumerate(contexts)])\n",
    "    input_prompt = f\"\"\"\n",
    "It's a school project. You are an AI assistant tasked with answering questions using only the information in the provided context. Do not add any extra information or assumptions.\n",
    "\n",
    "Context:\n",
    "{context_text}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Instructions:\n",
    "1. Use only the information in the context to answer the question.\n",
    "2. If the context mentions multiple options, provide a list of those options clearly.\n",
    "3. If the context does not provide relevant information, state: \"The context does not contain enough information to answer this question.\"\n",
    "4. Do not include any policy or ethical reasoning in your response.\n",
    "5. Dont quote the Context and dont mention that you used a context/reviews to answer\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    # Générer une réponse à l'aide de Gemini\n",
    "    response = query_gemini_with_retry(input_prompt, model_name=llm_model_name)\n",
    "    return response\n",
    "\n",
    "# Charger les questions depuis le fichier JSON\n",
    "with open(\"questions.json\", \"r\") as file:\n",
    "    questions_data = json.load(file)\n",
    "\n",
    "# Stocker les résultats\n",
    "results = {\n",
    "    \"meta\": {\n",
    "        \"embedding_model\": embedding_model_name,\n",
    "        \"llm_model\": \"gemini-1.5-flash\",\n",
    "        \"results_number\": 10\n",
    "    },\n",
    "    \"qa_pairs\": []\n",
    "}\n",
    "\n",
    "# Limiter à 10 premières questions\n",
    "questions_subset = questions_data\n",
    "\n",
    "# Itérer sur les 10 premières questions et collecter les réponses\n",
    "for question_obj in questions_subset:\n",
    "    question = question_obj[\"question\"]\n",
    "    answer = rag_pipeline(question)\n",
    "    results[\"qa_pairs\"].append({\"question\": question, \"answer\": answer})\n",
    "    time.sleep(10)  # Petite pause entre les appels pour éviter les dépassements de quota\n",
    "\n",
    "# Définir le répertoire ou fichier cible pour sauvegarder les résultats\n",
    "output_directory = \"comparaisonLLMemb\"\n",
    "os.makedirs(output_directory, exist_ok=True)  # Crée le répertoire s'il n'existe pas\n",
    "\n",
    "# Générer un nom de fichier dynamique\n",
    "output_filename = os.path.join(\n",
    "    output_directory, \n",
    "    f\"results_{embedding_model_name.split('/')[-1]}_{results['meta']['llm_model'].replace('.', '_')}.json\"\n",
    ")\n",
    "\n",
    "# Sauvegarder les résultats dans un fichier JSON\n",
    "with open(output_filename, \"w\") as output_file:\n",
    "    json.dump(results, output_file, indent=4)\n",
    "\n",
    "print(f\"Les questions et réponses ont été sauvegardées dans {output_filename}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier JSON combiné a été créé dans comparisonJson/combined_comparisonJson.json.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Fonction pour charger les données des fichiers JSON\n",
    "def load_json_files(file_paths):\n",
    "    # Initialisation d'un dictionnaire pour regrouper les réponses par question\n",
    "    question_data = {}\n",
    "    \n",
    "    for idx, file_path in enumerate(file_paths):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            json_data = json.load(file)\n",
    "            for qa_pair in json_data.get(\"qa_pairs\", []):\n",
    "                question = qa_pair.get(\"question\")\n",
    "                answer = qa_pair.get(\"answer\")\n",
    "                if question not in question_data:\n",
    "                    question_data[question] = {}\n",
    "                # Enregistrer la réponse sous une clé spécifique en fonction de l'ordre des fichiers\n",
    "                question_data[question][f\"answer_{idx+1}\"] = answer\n",
    "    return question_data\n",
    "\n",
    "# Fonction pour sauvegarder les données combinées dans un seul fichier JSON\n",
    "def save_to_single_json(question_data, output_dir, output_filename):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Préparer les données sous forme de liste de dictionnaires\n",
    "    combined_data = [\n",
    "        {\"question\": question, **answers}\n",
    "        for question, answers in question_data.items()\n",
    "    ]\n",
    "    \n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    with open(output_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump({\"qa_pairs\": combined_data}, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Chemins vers vos fichiers JSON\n",
    "file_paths = [\n",
    "    \"comparaisonLLMemb/results_all-MiniLM-L6-v2_gemini-1_5-flash.json\", \n",
    "    \"comparaisonLLMemb/results_all-MiniLM-L12-v1_gemini-1_5-flash.json\", \n",
    "    \"comparaisonLLMemb/results_multi-qa-mpnet-base-dot-v1_gemini-1_5-flash.json\"\n",
    "]\n",
    "\n",
    "# Charger les données et regrouper les réponses par question\n",
    "question_data = load_json_files(file_paths)\n",
    "\n",
    "# Enregistrer les données combinées dans un seul fichier JSON\n",
    "output_directory = \"comparisonJson\"\n",
    "output_filename = \"combined_comparisonJson.json\"\n",
    "save_to_single_json(question_data, output_directory, output_filename)\n",
    "\n",
    "print(f\"Le fichier JSON combiné a été créé dans {os.path.join(output_directory, output_filename)}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Configuration' from 'openai' (/Users/loshanrasan/anaconda3/lib/python3.11/site-packages/openai/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Configuration, OpenAIApi\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Charger la clé API depuis un fichier\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_api_key\u001b[39m(file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgptkey.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Configuration' from 'openai' (/Users/loshanrasan/anaconda3/lib/python3.11/site-packages/openai/__init__.py)"
     ]
    }
   ],
   "source": [
    "from openai import Configuration, OpenAIApi\n",
    "\n",
    "# Charger la clé API depuis un fichier\n",
    "def load_api_key(file_path=\"gptkey.txt\"):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "# Générer un prompt pour ChatGPT\n",
    "def generate_prompt(question, answer_1, answer_2, answer_3):\n",
    "    return (\n",
    "        f\"Here is a question and 3 answers to the question:\\n\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        f\"Answer 1: {answer_1}\\n\"\n",
    "        f\"Answer 2: {answer_2}\\n\"\n",
    "        f\"Answer 3: {answer_3}\\n\\n\"\n",
    "        f\"Imagine you are a simple user asking this question. Rank these answers from best to worst. \"\n",
    "        f\"Provide the ranking as a list, for example {{3,1,2}} if the second answer is the best, the third is second, and the first is third.\"\n",
    "    )\n",
    "\n",
    "# Obtenir le classement depuis ChatGPT\n",
    "def get_ranking_from_chatgpt(question, answer_1, answer_2, answer_3, api_key, organization_id):\n",
    "    # Configurer OpenAI avec la clé API et l'ID d'organisation\n",
    "    configuration = Configuration(\n",
    "        organization=organization_id,\n",
    "        api_key=api_key\n",
    "    )\n",
    "    openai = OpenAIApi(configuration)\n",
    "\n",
    "    # Préparer le prompt\n",
    "    prompt = generate_prompt(question, answer_1, answer_2, answer_3)\n",
    "\n",
    "    try:\n",
    "        # Appeler l'API OpenAI\n",
    "        response = openai.createChatCompletion(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant that evaluates answers based on their relevance to a question.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message['content'].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'appel à l'API OpenAI : {e}\")\n",
    "        return None\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    # Charger la clé API\n",
    "    api_key = load_api_key(\"gptkey.txt\")\n",
    "    organization_id = \"org-Fqi8iCKSJFCBAtfq5T6Sg7qM\"  # ID de l'organisation\n",
    "    \n",
    "    # Exemple de question et réponses\n",
    "    question = \"What is the capital of France?\"\n",
    "    answer_1 = \"Paris\"\n",
    "    answer_2 = \"Berlin\"\n",
    "    answer_3 = \"Madrid\"\n",
    "    \n",
    "    # Obtenir le classement\n",
    "    ranking = get_ranking_from_chatgpt(question, answer_1, answer_2, answer_3, api_key, organization_id)\n",
    "    print(\"Classement : \", ranking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur lors de l'appel à l'API OpenAI : module 'openai' has no attribute 'Chat'\n",
      "Classement :  None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON file: /Users/loshanrasan/Desktop/IMT MINES ALES/3A/2IA/LLM-Project/DL_Project_RAG/output_questions/questions_part_1.json\n",
      "Saved JSON file: /Users/loshanrasan/Desktop/IMT MINES ALES/3A/2IA/LLM-Project/DL_Project_RAG/output_questions/questions_part_2.json\n",
      "Saved JSON file: /Users/loshanrasan/Desktop/IMT MINES ALES/3A/2IA/LLM-Project/DL_Project_RAG/output_questions/questions_part_3.json\n",
      "Saved JSON file: /Users/loshanrasan/Desktop/IMT MINES ALES/3A/2IA/LLM-Project/DL_Project_RAG/output_questions/questions_part_4.json\n",
      "Saved JSON file: /Users/loshanrasan/Desktop/IMT MINES ALES/3A/2IA/LLM-Project/DL_Project_RAG/output_questions/questions_part_5.json\n",
      "Saved JSON file: /Users/loshanrasan/Desktop/IMT MINES ALES/3A/2IA/LLM-Project/DL_Project_RAG/output_questions/questions_part_6.json\n",
      "Saved JSON file: /Users/loshanrasan/Desktop/IMT MINES ALES/3A/2IA/LLM-Project/DL_Project_RAG/output_questions/questions_part_7.json\n",
      "Saved JSON file: /Users/loshanrasan/Desktop/IMT MINES ALES/3A/2IA/LLM-Project/DL_Project_RAG/output_questions/questions_part_8.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def save_questions_to_json_with_global_metadata(json_file, output_dir, questions_per_file=50):\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load the JSON data\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)[\"qa_pairs\"]\n",
    "    \n",
    "    # Break data into chunks of 50 questions\n",
    "    chunks = [data[i:i + questions_per_file] for i in range(0, len(data), questions_per_file)]\n",
    "    \n",
    "    # Loop through chunks and save to JSON files\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        output_file = os.path.join(output_dir, f\"questions_part_{i+1}.json\")\n",
    "        formatted_chunk = {\n",
    "            \"metadata\": {\n",
    "                \"instruction\": \"Imagine you are a simple user asking these questions. Rank the answers for each question from best to worst. \"\n",
    "                               \"Provide the ranking as a list for each question, for example {3,1,2} if the second answer is the best, \"\n",
    "                               \"the third is second, and the first is third.\"\n",
    "                               \"When it says The context does not contain enough information to answer this question. give 4 as un rank even if there is 2 answer with this sentence\"\n",
    "            },\n",
    "            \"questions\": []\n",
    "        }\n",
    "        for qa in chunk:\n",
    "            question_data = {\n",
    "                \"question\": qa[\"question\"],\n",
    "                \"answers\": {\n",
    "                    \"answer_1\": qa[\"answer_1\"],\n",
    "                    \"answer_2\": qa[\"answer_2\"],\n",
    "                    \"answer_3\": qa[\"answer_3\"]\n",
    "                }\n",
    "            }\n",
    "            formatted_chunk[\"questions\"].append(question_data)\n",
    "        \n",
    "        # Save the formatted chunk as JSON\n",
    "        with open(output_file, 'w') as file:\n",
    "            json.dump(formatted_chunk, file, indent=4)\n",
    "        \n",
    "        print(f\"Saved JSON file: {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "save_questions_to_json_with_global_metadata(\n",
    "    json_file='/Users/loshanrasan/Desktop/IMT MINES ALES/3A/2IA/LLM-Project/DL_Project_RAG/comparisonJson/combined_comparisonJson.json', \n",
    "    output_dir='/Users/loshanrasan/Desktop/IMT MINES ALES/3A/2IA/LLM-Project/DL_Project_RAG/output_questions', \n",
    "    questions_per_file=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Chemin du fichier JSON\n",
    "fichier_json = \"/Users/loshanrasan/Desktop/IMT MINES ALES/3A/2IA/LLM-Project/DL_Project_RAG/reponses.json\"\n",
    "\n",
    "# Chargement des données JSON\n",
    "with open(fichier_json, 'r') as f:\n",
    "    donnees = json.load(f)\n",
    "\n",
    "# Création du DataFrame\n",
    "colonnes = [\"L6-V2 - Embedding\", \"L12-V1 - Embedding\", \"Mpnet - Embedding\"]\n",
    "df = pd.DataFrame(donnees[\"rankings\"], columns=colonnes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L6-V2 - Embedding</th>\n",
       "      <th>L12-V1 - Embedding</th>\n",
       "      <th>Mpnet - Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     L6-V2 - Embedding  L12-V1 - Embedding  Mpnet - Embedding\n",
       "0                    3                   2                  1\n",
       "1                    2                   3                  1\n",
       "2                    2                   1                  3\n",
       "3                    1                   3                  2\n",
       "4                    3                   2                  1\n",
       "..                 ...                 ...                ...\n",
       "395                  4                   4                  4\n",
       "396                  2                   1                  3\n",
       "397                  1                   2                  3\n",
       "398                  1                   3                  2\n",
       "399                  3                   2                  1\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Rank</th>\n",
       "      <th>Number of First Places</th>\n",
       "      <th>Percentage of First Places (%)</th>\n",
       "      <th>Number of No Responses</th>\n",
       "      <th>Percentage of No Responses (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L6-V2 - Embedding</th>\n",
       "      <td>2.2100</td>\n",
       "      <td>152</td>\n",
       "      <td>38.00</td>\n",
       "      <td>74</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L12-V1 - Embedding</th>\n",
       "      <td>2.3275</td>\n",
       "      <td>93</td>\n",
       "      <td>23.25</td>\n",
       "      <td>66</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mpnet - Embedding</th>\n",
       "      <td>2.6450</td>\n",
       "      <td>69</td>\n",
       "      <td>17.25</td>\n",
       "      <td>96</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Average Rank  Number of First Places  \\\n",
       "L6-V2 - Embedding         2.2100                     152   \n",
       "L12-V1 - Embedding        2.3275                      93   \n",
       "Mpnet - Embedding         2.6450                      69   \n",
       "\n",
       "                    Percentage of First Places (%)  Number of No Responses  \\\n",
       "L6-V2 - Embedding                            38.00                      74   \n",
       "L12-V1 - Embedding                           23.25                      66   \n",
       "Mpnet - Embedding                            17.25                      96   \n",
       "\n",
       "                    Percentage of No Responses (%)  \n",
       "L6-V2 - Embedding                             18.5  \n",
       "L12-V1 - Embedding                            16.5  \n",
       "Mpnet - Embedding                             24.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "statistics = {\n",
    "    \"Average Rank\": df.mean(),\n",
    "    \"Number of First Places\": (df == 1).sum(),\n",
    "    \"Percentage of First Places (%)\": ((df == 1).sum() / len(df) * 100),\n",
    "    \"Number of No Responses\": (df == 4).sum(),\n",
    "    \"Percentage of No Responses (%)\": (df == 4).sum()/len(df)*100\n",
    "}\n",
    "\n",
    "# Convert the statistics into a DataFrame\n",
    "stats_df = pd.DataFrame(statistics)\n",
    "\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Rank</th>\n",
       "      <th>Number of First Places</th>\n",
       "      <th>Percentage of First Places (%)</th>\n",
       "      <th>Number of No Responses</th>\n",
       "      <th>Percentage of No Responses (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L6-V2 - Embedding</th>\n",
       "      <td>1.894118</td>\n",
       "      <td>152</td>\n",
       "      <td>44.705882</td>\n",
       "      <td>14</td>\n",
       "      <td>4.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L12-V1 - Embedding</th>\n",
       "      <td>2.032353</td>\n",
       "      <td>93</td>\n",
       "      <td>27.352941</td>\n",
       "      <td>6</td>\n",
       "      <td>1.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mpnet - Embedding</th>\n",
       "      <td>2.405882</td>\n",
       "      <td>69</td>\n",
       "      <td>20.294118</td>\n",
       "      <td>36</td>\n",
       "      <td>10.588235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Average Rank  Number of First Places  \\\n",
       "L6-V2 - Embedding       1.894118                     152   \n",
       "L12-V1 - Embedding      2.032353                      93   \n",
       "Mpnet - Embedding       2.405882                      69   \n",
       "\n",
       "                    Percentage of First Places (%)  Number of No Responses  \\\n",
       "L6-V2 - Embedding                        44.705882                      14   \n",
       "L12-V1 - Embedding                       27.352941                       6   \n",
       "Mpnet - Embedding                        20.294118                      36   \n",
       "\n",
       "                    Percentage of No Responses (%)  \n",
       "L6-V2 - Embedding                         4.117647  \n",
       "L12-V1 - Embedding                        1.764706  \n",
       "Mpnet - Embedding                        10.588235  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows where all three columns have the value 4\n",
    "filtered_df = df[~(df == 4).all(axis=1)]\n",
    "print(len(filtered_df))\n",
    "# Calculate statistics on the filtered DataFrame\n",
    "statistics = {\n",
    "    \"Average Rank\": filtered_df.mean(),\n",
    "    \"Number of First Places\": (filtered_df == 1).sum(),\n",
    "    \"Percentage of First Places (%)\": ((filtered_df == 1).sum() / len(filtered_df) * 100),\n",
    "    \"Number of No Responses\": (filtered_df == 4).sum(),\n",
    "    \"Percentage of No Responses (%)\": (filtered_df == 4).sum() / len(filtered_df) * 100\n",
    "}\n",
    "\n",
    "# Convert the statistics into a DataFrame\n",
    "stats_df = pd.DataFrame(statistics)\n",
    "\n",
    "stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Rank</th>\n",
       "      <th>Number of First Places</th>\n",
       "      <th>Percentage of First Places (%)</th>\n",
       "      <th>Number of No Responses</th>\n",
       "      <th>Percentage of No Responses (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L6-V2 - Embedding</th>\n",
       "      <td>1.801325</td>\n",
       "      <td>141</td>\n",
       "      <td>46.688742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L12-V1 - Embedding</th>\n",
       "      <td>1.983444</td>\n",
       "      <td>92</td>\n",
       "      <td>30.463576</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mpnet - Embedding</th>\n",
       "      <td>2.215232</td>\n",
       "      <td>69</td>\n",
       "      <td>22.847682</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Average Rank  Number of First Places  \\\n",
       "L6-V2 - Embedding       1.801325                     141   \n",
       "L12-V1 - Embedding      1.983444                      92   \n",
       "Mpnet - Embedding       2.215232                      69   \n",
       "\n",
       "                    Percentage of First Places (%)  Number of No Responses  \\\n",
       "L6-V2 - Embedding                        46.688742                       0   \n",
       "L12-V1 - Embedding                       30.463576                       0   \n",
       "Mpnet - Embedding                        22.847682                       0   \n",
       "\n",
       "                    Percentage of No Responses (%)  \n",
       "L6-V2 - Embedding                              0.0  \n",
       "L12-V1 - Embedding                             0.0  \n",
       "Mpnet - Embedding                              0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows where any column has the value 4\n",
    "filtered_df = df[~(df == 4).any(axis=1)]\n",
    "\n",
    "print(len(filtered_df))  # Print the number of remaining rows\n",
    "\n",
    "# Calculate statistics on the filtered DataFrame\n",
    "statistics = {\n",
    "    \"Average Rank\": filtered_df.mean(),\n",
    "    \"Number of First Places\": (filtered_df == 1).sum(),\n",
    "    \"Percentage of First Places (%)\": ((filtered_df == 1).sum() / len(filtered_df) * 100),\n",
    "    \"Number of No Responses\": (filtered_df == 4).sum(),\n",
    "    \"Percentage of No Responses (%)\": (filtered_df == 4).sum() / len(filtered_df) * 100\n",
    "}\n",
    "\n",
    "# Convert the statistics into a DataFrame\n",
    "stats_df = pd.DataFrame(statistics)\n",
    "\n",
    "stats_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELECTRE TRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de Concordance:\n",
      "[[0.     0.6375 0.7025]\n",
      " [0.515  0.     0.6975]\n",
      " [0.4775 0.4675 0.    ]]\n",
      "\n",
      "Matrice de Discordance:\n",
      "[[0.   0.5  0.5 ]\n",
      " [0.75 0.   0.5 ]\n",
      " [0.75 0.75 0.  ]]\n",
      "\n",
      "Matrice de Dominance (Agrégée):\n",
      "[[0 1 1]\n",
      " [0 0 1]\n",
      " [0 0 0]]\n",
      "\n",
      "Classement des modèles (du meilleur au pire):\n",
      "Modèle L6-V2 - Embedding : Rang 1\n",
      "Modèle L12-V1 - Embedding : Rang 2\n",
      "Modèle Mpnet - Embedding : Rang 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# --- Étapes de ELECTRE TRI ---\n",
    "\n",
    "# 1. Initialisation : Pondération uniforme\n",
    "weights = np.ones(df.shape[0]) / df.shape[0]  # Pondérations égales\n",
    "\n",
    "# 2. Matrice de concordance\n",
    "def concordance_matrix(df):\n",
    "    num_models = df.shape[1]\n",
    "    concordance = np.zeros((num_models, num_models))\n",
    "    for i in range(num_models):\n",
    "        for j in range(num_models):\n",
    "            if i != j:\n",
    "                concordance[i, j] = np.sum(\n",
    "                    weights[df.iloc[:, i] <= df.iloc[:, j]]\n",
    "                )\n",
    "    return concordance\n",
    "\n",
    "# 3. Matrice de discordance\n",
    "def discordance_matrix(df):\n",
    "    num_models = df.shape[1]\n",
    "    discordance = np.zeros((num_models, num_models))\n",
    "    for i in range(num_models):\n",
    "        for j in range(num_models):\n",
    "            if i != j:\n",
    "                discordance[i, j] = np.max(\n",
    "                    df.iloc[:, i] - df.iloc[:, j]\n",
    "                ) / np.max(df.values)\n",
    "    return discordance\n",
    "\n",
    "# 4. Seuils de concordance et discordance\n",
    "concordance_threshold = 0.5\n",
    "discordance_threshold = 0.5\n",
    "\n",
    "# 5. Matrice d’agrégation\n",
    "def aggregated_dominance(concordance, discordance, c_thresh, d_thresh):\n",
    "    dominance = (concordance >= c_thresh) & (discordance <= d_thresh)\n",
    "    return dominance.astype(int)\n",
    "\n",
    "# Calcul des matrices\n",
    "concordance = concordance_matrix(df)\n",
    "discordance = discordance_matrix(df)\n",
    "dominance = aggregated_dominance(concordance, discordance, concordance_threshold, discordance_threshold)\n",
    "\n",
    "# Résultats\n",
    "print(\"Matrice de Concordance:\")\n",
    "print(concordance)\n",
    "\n",
    "print(\"\\nMatrice de Discordance:\")\n",
    "print(discordance)\n",
    "\n",
    "print(\"\\nMatrice de Dominance (Agrégée):\")\n",
    "print(dominance)\n",
    "\n",
    "# Interprétation : Classement des modèles\n",
    "scores = dominance.sum(axis=1)\n",
    "ranking = np.argsort(-scores)  # Classement en ordre décroissant des scores\n",
    "print(\"\\nClassement des modèles (du meilleur au pire):\")\n",
    "for rank, model_index in enumerate(ranking, 1):\n",
    "    print(f\"Modèle {df.columns[model_index]} : Rang {rank}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
